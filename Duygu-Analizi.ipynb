{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "e50cb347",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: nltk in d:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tweepy in d:\\programdata\\anaconda3\\lib\\site-packages (4.12.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (2.28.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in d:\\programdata\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wordcloud in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: pillow in d:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: matplotlib in d:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in d:\\programdata\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: click in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in d:\\programdata\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.4.4)\n",
      "Requirement already satisfied: scipy>=1.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.9.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement poyraz (from versions: none)\n",
      "ERROR: No matching distribution found for poyraz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (3.4.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: setuptools in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.11)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (8.1.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (0.0.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: zemberek-python in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (0.2.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from zemberek-python) (1.21.5)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from zemberek-python) (4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: trnltk in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (0.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/emres/turkish-deasciifier.git\n",
      "  Cloning https://github.com/emres/turkish-deasciifier.git to c:\\users\\cemke\\appdata\\local\\temp\\pip-req-build-2fi4_6eh\n",
      "  Resolved https://github.com/emres/turkish-deasciifier.git to commit 665154c734b09485c3d11ce0038cd121dd109594\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/emres/turkish-deasciifier.git 'C:\\Users\\cemke\\AppData\\Local\\Temp\\pip-req-build-2fi4_6eh'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (4.25.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (2.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: dill<0.3.7 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pandas in d:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: packaging in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.29.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install tweepy\n",
    "%pip install pandas\n",
    "%pip install wordcloud\n",
    "%pip install textblob\n",
    "%pip install seaborn\n",
    "%pip install poyraz\n",
    "%pip install spacy\n",
    "%pip install sklearn\n",
    "%pip install zemberek-python\n",
    "%pip install trnltk\n",
    "%pip install git+https://github.com/emres/turkish-deasciifier.git\n",
    "%pip install transformers datasets\n",
    "%pip install torch\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "f73c9b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cemke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*-coding:utf-8-*-\n",
    "from zemberek import (\n",
    "    TurkishSpellChecker,\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishTokenizer\n",
    ")\n",
    "import logging\n",
    "import tweepy\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "import string\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import Stream\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "from trnlp import TrnlpWord\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, TextClassificationPipeline\n",
    "from transformers import pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "31c724d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getTweets:\n",
    "    def __init__(self,ckey,csecret,atoken,asecret):\n",
    "        self.api=None\n",
    "        self.consumer_key = ckey\n",
    "        self.consumer_secret = csecret\n",
    "        self.access_token = atoken\n",
    "        self.access_token_secret = asecret\n",
    "        \n",
    "    def setAuth(self):\n",
    "        try:\n",
    "            self.auth = tweepy.OAuthHandler(self.consumer_key, self.consumer_secret)\n",
    "            self.auth.set_access_token(self.access_token, self.access_token_secret)\n",
    "            self.api = tweepy.API(self.auth)            \n",
    "            print (\"BaÄŸlantÄ± YapÄ±ldÄ±!\")                           \n",
    "        except tweepy.TweepError as err:\n",
    "            print('Error: {}'.format(err))   \n",
    "    \n",
    "    def toDataFrame(tweets):\n",
    "        try:\n",
    "            print (\"Veriler KayÄ±t Ediliyor...\")\n",
    "            pd.set_option('display.max_rows', None)\n",
    "            pd.set_option('display.max_columns', None)\n",
    "            pd.set_option('display.width', None)\n",
    "            pd.set_option('display.max_colwidth', None)\n",
    "            DataSet = pd.DataFrame()\n",
    "\n",
    "            DataSet['KullanÄ±cÄ±_AdÄ±'] = [tweet.user.name for tweet in tweets]\n",
    "            DataSet['Tweet_Tarih'] = [tweet.created_at for tweet in tweets]   \n",
    "            #DataSet['Tweet_Id'] = [tweet.id for tweet in tweets]\n",
    "            DataSet['Tweet'] = [tweet.text for tweet in tweets]\n",
    "            DataSet['Tweet_Degistirilmis'] = [tweet.text for tweet in tweets]\n",
    "            DataSet['Tweet_Ceviri']=[tweet.text for tweet in tweets]            \n",
    "            #DataSet['KullanÄ±cÄ±_Id'] = [tweet.user.id for tweet in tweets]  \n",
    "                \n",
    "            #DataSet['Dil'] = [tweet.lang for tweet in tweets]\n",
    "            print (\"Veriler KayÄ±t Edildi!\")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "    \n",
    "    def searchTweet(self,aranan):\n",
    "        self.setAuth()\n",
    "        try:                      \n",
    "            print (\"Kelimeye Uygun Tweetler SorgulanÄ±yor...\")\n",
    "            cursor = tweepy.Cursor(self.api.search_tweets, q=aranan, result_type=\"mixed\", lang='tr')\n",
    "            results=[]\n",
    "            for item in cursor.items(10):\n",
    "                results.append(item)\n",
    "            print (\"Kelimeye Uygun Tweetler SorgulandÄ±!\")\n",
    "            DataSet = getTweets.toDataFrame(results)  \n",
    "            DataSet.to_csv('tw.csv')\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "        finally:\n",
    "            Dataset=pd.read_csv('tw.csv')                   \n",
    "            getTweets.TweetClear(DataSet)\n",
    "            getTweets.SentenceNormalization(DataSet)\n",
    "            getTweets.TweetTranslate(DataSet)\n",
    "            getTweets.KelimeAyristirma(DataSet) \n",
    "            getTweets.ToxicSentiment(DataSet)\n",
    "            getTweets.TextblobSentiment(DataSet)\n",
    "\n",
    "    def TextblobSentiment(DataSet):\n",
    "        try:\n",
    "            print (\"Duygu Analizi YapÄ±lÄ±yor...\")\n",
    "            Veri=DataSet\n",
    "            Veri[\"TÃ¼r\"] = Veri[\"Tweet_AyrÄ±\"].apply(getTweets.getPolarity)\n",
    "            Veri[\"YoÄŸunluk\"] = Veri[\"Tweet_AyrÄ±\"].apply(getTweets.getSubjectivity)\n",
    "            Veri.to_csv('textblob_eng_duygu.csv',index=False)\n",
    "            print(\"Duygu Analizi YapÄ±ldÄ±!\")                        \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \n",
    "            \n",
    "    \"\"\"def TrSentiment(DataSet):\n",
    "        try:\n",
    "            print(\"TÃ¼rkÃ§e Duygu Analizi YapÄ±lÄ±yor...\")\n",
    "            for example,index in DataSet[\"Tweet_Degistirilmis\"]:\n",
    "                DataSet[\"TR_A\"][index] = simple_token(example, sw=stopwords)\n",
    "            print(\"TÃ¼rkÃ§e Duygu Analizi YapÄ±ldÄ±!\")\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \"\"\"\n",
    "    def TweetClear(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print (\"Tweetler Temizleniyor...\")\n",
    "            pattern = re.compile('http[s]?://(?:[a-zA-Z0-9ÄŸÃ¼ÅŸÃ¶Ã§Ä±Ä°ÄÃœÅÃ–Ã‡]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F]))+|#[a-zA-Z0-9ÄŸÃ¼ÅŸÃ¶Ã§Ä±Ä°ÄÃœÅÃ–Ã‡]+|$[a-zA-ZÄŸÃ¼ÅŸÃ¶Ã§Ä±Ä°ÄÃœÅÃ–Ã‡]+|@[a-zA-Z0-9ÄŸÃ¼ÅŸÃ¶Ã§Ä±Ä°ÄÃœÅÃ–Ã‡_]+|[,.^_$*%-;é¶¯!?â€™\"â€œâ€:=|â€¦#]+|\\n+|RT[\\s]+|amp[\\s]+|(^gt)')\n",
    "            for index in range(len(data[\"Tweet_Degistirilmis\"])):        \n",
    "                data[\"Tweet_Degistirilmis\"][index]=pattern.sub(' ', data[\"Tweet_Degistirilmis\"][index])    \n",
    "                data[\"Tweet_Degistirilmis\"][index]=data[\"Tweet_Degistirilmis\"][index].lower()              \n",
    "            data[\"Tweet_Degistirilmis\"]=data[\"Tweet_Degistirilmis\"].str.replace(\"[^\\w\\s]\",\"\")\n",
    "            print (\"Tweetler Temizlendi!\")\n",
    "            return data\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))  \n",
    "                              \n",
    "    def TweetTranslate(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print (\"Tweetler Ã‡eviriliyor...\")\n",
    "            for index in range(len(data[\"Tweet_Degistirilmis\"])):\n",
    "                Ceviri_Blob=TextBlob(data[\"Tweet_Degistirilmis\"][index])\n",
    "                Eng_Blob=Ceviri_Blob.translate(from_lang='tr', to='en')  \n",
    "                data[\"Tweet_Ceviri\"][index]=Eng_Blob.lower()                \n",
    "            print (\"Tweetler Ã‡evirildi!\")                      \n",
    "            return data        \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \n",
    "            \n",
    "    def SentenceNormalization(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print(\"CÃ¼mle Normalizasyonu YapÄ±lÄ±yor...\")\n",
    "            logger = logging.getLogger(__name__)            \n",
    "            morphology = TurkishMorphology.create_with_defaults()\n",
    "            normalizer = TurkishSentenceNormalizer(morphology)\n",
    "            for index in range(len(data[\"Tweet_Degistirilmis\"])):                \n",
    "                data[\"Tweet_Degistirilmis\"][index]= normalizer.normalize(data[\"Tweet_Degistirilmis\"][index])\n",
    "            print(\"CÃ¼mle Normalizasyonu YapÄ±ldÄ±!\")\n",
    "            sc = TurkishSpellChecker(morphology)\n",
    "            return data\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def KelimeAyristirma(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            stop = stopwords.words('english')\n",
    "            data[\"Tweet_AyrÄ±\"] = data[\"Tweet_Ceviri\"].str.split()\n",
    "            data[\"Tweet_AyrÄ±\"] = data[\"Tweet_AyrÄ±\"].apply(lambda x: [item for item in x if item not in stop])\n",
    "            data[\"Tweet_AyrÄ±\"] = data[\"Tweet_AyrÄ±\"].str.join(\" \")\n",
    "            return data\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "    \n",
    "    def ToxicSentiment(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print(\"Toxic CÃ¼mle Analizi YapÄ±lÄ±yor...\")\n",
    "            model_path =\"martin-ha/toxic-comment-model\"\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "            model=AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "            pipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "            for index in range(len(data[\"Tweet_Ceviri\"])):\n",
    "                sonuc=pipeline(str(data[\"Tweet_Toxic\"][index]))\n",
    "                if sonuc[0]['label']==\"toxic\":\n",
    "                    data[\"Tweet_Toxic\"][index]=\"Toxic\"\n",
    "                else:\n",
    "                    data[\"Tweet_Toxic\"][index]=\"Toxic deÄŸil\"    \n",
    "            print(\"Toxic CÃ¼mle Analizi YapÄ±ldÄ±!\")\n",
    "            return data  \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "        \n",
    "    def getSubjectivity(DataSet):\n",
    "        try: \n",
    "            sub=TextBlob(DataSet).sentiment.subjectivity               \n",
    "            if sub >=0.75:\n",
    "                return \"%75 - %100\"\n",
    "            elif sub >=0.5 and sub <0.75:\n",
    "                return \"%50 - %75\"\n",
    "            elif sub >=0.25 and sub <0.50:\n",
    "                return \"%25 - %50\"\n",
    "            else:\n",
    "                return \"0 - 25%\"\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def getPolarity(DataSet):\n",
    "        try:\n",
    "            pol=TextBlob(DataSet).sentiment.polarity\n",
    "            if pol>0.3:\n",
    "                return \"Pozitif\"\n",
    "            elif pol<-0.3:\n",
    "                return \"Negatif\"\n",
    "            else:\n",
    "                return \"NÃ¶tr\"\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "cc4db959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaÄŸlantÄ± YapÄ±ldÄ±!\n",
      "Kelimeye Uygun Tweetler SorgulanÄ±yor...\n",
      "Kelimeye Uygun Tweetler SorgulandÄ±!\n",
      "Veriler KayÄ±t Ediliyor...\n",
      "Veriler KayÄ±t Edildi!\n",
      "Tweetler Temizleniyor...\n",
      "Tweetler Temizlendi!\n",
      "CÃ¼mle Normalizasyonu YapÄ±lÄ±yor...\n",
      "2023-01-12 05:30:10,185 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 9.684077739715576\n",
      "\n",
      "CÃ¼mle Normalizasyonu YapÄ±ldÄ±!\n",
      "Tweetler Ã‡eviriliyor...\n",
      "Tweetler Ã‡evirildi!\n",
      "Toxic CÃ¼mle Analizi YapÄ±lÄ±yor...\n",
      "Error: 'Tweet_Toxic'\n",
      "Duygu Analizi YapÄ±lÄ±yor...\n",
      "Duygu Analizi YapÄ±ldÄ±!\n"
     ]
    }
   ],
   "source": [
    "tw = getTweets( \n",
    "ckey = 'o7qidRODRWm5u07PtAWrCpSqf',\n",
    "csecret = '1Yn60OYMJl5kRCSM0XQ4Lskxh6hjM4VMz51OdsS6dM9DQuQ4MV',\n",
    "atoken = '1315792402234441730-Dt7AydgVGYI5VN9RRQfnR8Endh0WAc',\n",
    "asecret = 'jhfiDfB53Z27EqHfvfKbNdo0w2SWLqyyoAkILqgSoaGMK'\n",
    ")\n",
    "aranan=input(\"Aranacak Kelimeyi Girin: \")\n",
    "tw.searchTweet(aranan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "e018df1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KullanÄ±cÄ±_AdÄ±</th>\n",
       "      <th>Tweet_Tarih</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_Degistirilmis</th>\n",
       "      <th>Tweet_Ceviri</th>\n",
       "      <th>Tweet_AyrÄ±</th>\n",
       "      <th>TÃ¼r</th>\n",
       "      <th>YoÄŸunluk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T.C. TarÄ±m ve Orman BakanlÄ±ÄŸÄ±</td>\n",
       "      <td>2023-01-02 13:23:39+00:00</td>\n",
       "      <td>TarÄ±mCebimde mobil uygulamasÄ± ile tarÄ±mla ilgili birÃ§ok bilgi ve iÅŸlem artÄ±k bir tÄ±k uzaÄŸÄ±nÄ±zdağŸ‘‡ğŸ»\\n\\nApp Storeâ€¦ https://t.co/J3lWZUoPge</td>\n",
       "      <td>tarÄ±mcebimde mobil uygulamasÄ± ile tarÄ±mla ilgili birÃ§ok bilgi ve iÅŸlem artÄ±k bir tÄ±k uzaÄŸÄ±nÄ±zda appstore</td>\n",
       "      <td>many information and transactions related to agriculture with the mobile application in agriculture now are now a click away appstore</td>\n",
       "      <td>many information transactions related agriculture mobile application agriculture click away appstore</td>\n",
       "      <td>NÃ¶tr</td>\n",
       "      <td>%25 - %50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TÃ¼rk Polis TeÅŸkilatÄ±</td>\n",
       "      <td>2023-01-03 08:39:07+00:00</td>\n",
       "      <td>#UYUMA uygulamasÄ± ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z uyuÅŸturucu ticaretini doÄŸrudan ve en hÄ±zlÄ± ÅŸekilde bildirin!\\n\\nUygulamayÄ± indiâ€¦ https://t.co/8WaLKZsD5j</td>\n",
       "      <td>uygulamasÄ± ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z uyuÅŸturucu ticaretini doÄŸrudan ve en hÄ±zlÄ± ÅŸekilde bildirin uygulamayÄ± indi</td>\n",
       "      <td>report the drug trade directly and fastest in the fastest way.</td>\n",
       "      <td>report drug trade directly fastest fastest way.</td>\n",
       "      <td>NÃ¶tr</td>\n",
       "      <td>%25 - %50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mÃ¼thiÅŸ indirim</td>\n",
       "      <td>2023-01-11 16:35:28+00:00</td>\n",
       "      <td>AkÄ±llÄ± Saatler KÄ±sa SÃ¼reliÄŸine Ä°ndirimde KaÃ§Ä±rmayÄ±nnâŒšï¸ğŸ”¥\\n\\nğŸ”— https://t.co/tfJO1ZAeQb https://t.co/yx5JcK4Svl</td>\n",
       "      <td>akÄ±llÄ± saatler kÄ±sa sÃ¼reliÄŸine indirimde kaÃ§Ä±rmayÄ±n</td>\n",
       "      <td>smart watches do not miss for a short time</td>\n",
       "      <td>smart watches miss short time</td>\n",
       "      <td>NÃ¶tr</td>\n",
       "      <td>%25 - %50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cigdem Kaya</td>\n",
       "      <td>2023-01-12 02:27:15+00:00</td>\n",
       "      <td>RT @CanSelcuki: Ocak ayÄ± anketi tamamlandÄ±. \\n\\n- AK Parti yÃ¼kseliÅŸ trendi devam ediyor\\n- KararsÄ±zlarda anlamlÄ± bir dÃ¼ÅŸÃ¼ÅŸ var\\n- EYT toplumunâ€¦</td>\n",
       "      <td>ocak ayÄ± anketi tamamlandÄ± ak parti yÃ¼kseliÅŸ trendi devam ediyor kararsÄ±zlarda anlamlÄ± bir dÃ¼ÅŸÃ¼ÅŸ var eyt toplumun</td>\n",
       "      <td>january survey was completed, the ak party rise trend continues, there is a significant decrease in the undecided.</td>\n",
       "      <td>january survey completed, ak party rise trend continues, significant decrease undecided.</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>%75 - %100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Halit Ã‡elik</td>\n",
       "      <td>2023-01-12 02:26:55+00:00</td>\n",
       "      <td>Benim de oynadÄ±ÄŸÄ±m Futbol Patronu iPhone oyununu bir dene https://t.co/41pSGJjSfc</td>\n",
       "      <td>benim de oynadÄ±ÄŸÄ±m futbol patronu Ä±phone oyununu bir dene</td>\n",
       "      <td>try the football boss i play a game of iphone.</td>\n",
       "      <td>try football boss play game iphone.</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>%25 - %50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   KullanÄ±cÄ±_AdÄ±                Tweet_Tarih  \\\n",
       "0  T.C. TarÄ±m ve Orman BakanlÄ±ÄŸÄ±  2023-01-02 13:23:39+00:00   \n",
       "1           TÃ¼rk Polis TeÅŸkilatÄ±  2023-01-03 08:39:07+00:00   \n",
       "2                 mÃ¼thiÅŸ indirim  2023-01-11 16:35:28+00:00   \n",
       "3                    Cigdem Kaya  2023-01-12 02:27:15+00:00   \n",
       "4                    Halit Ã‡elik  2023-01-12 02:26:55+00:00   \n",
       "\n",
       "                                                                                                                                             Tweet  \\\n",
       "0          TarÄ±mCebimde mobil uygulamasÄ± ile tarÄ±mla ilgili birÃ§ok bilgi ve iÅŸlem artÄ±k bir tÄ±k uzaÄŸÄ±nÄ±zdağŸ‘‡ğŸ»\\n\\nApp Storeâ€¦ https://t.co/J3lWZUoPge   \n",
       "1   #UYUMA uygulamasÄ± ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z uyuÅŸturucu ticaretini doÄŸrudan ve en hÄ±zlÄ± ÅŸekilde bildirin!\\n\\nUygulamayÄ± indiâ€¦ https://t.co/8WaLKZsD5j   \n",
       "2                                     AkÄ±llÄ± Saatler KÄ±sa SÃ¼reliÄŸine Ä°ndirimde KaÃ§Ä±rmayÄ±nnâŒšï¸ğŸ”¥\\n\\nğŸ”— https://t.co/tfJO1ZAeQb https://t.co/yx5JcK4Svl   \n",
       "3  RT @CanSelcuki: Ocak ayÄ± anketi tamamlandÄ±. \\n\\n- AK Parti yÃ¼kseliÅŸ trendi devam ediyor\\n- KararsÄ±zlarda anlamlÄ± bir dÃ¼ÅŸÃ¼ÅŸ var\\n- EYT toplumunâ€¦   \n",
       "4                                                                Benim de oynadÄ±ÄŸÄ±m Futbol Patronu iPhone oyununu bir dene https://t.co/41pSGJjSfc   \n",
       "\n",
       "                                                                                                 Tweet_Degistirilmis  \\\n",
       "0           tarÄ±mcebimde mobil uygulamasÄ± ile tarÄ±mla ilgili birÃ§ok bilgi ve iÅŸlem artÄ±k bir tÄ±k uzaÄŸÄ±nÄ±zda appstore   \n",
       "1         uygulamasÄ± ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z uyuÅŸturucu ticaretini doÄŸrudan ve en hÄ±zlÄ± ÅŸekilde bildirin uygulamayÄ± indi   \n",
       "2                                                                akÄ±llÄ± saatler kÄ±sa sÃ¼reliÄŸine indirimde kaÃ§Ä±rmayÄ±n   \n",
       "3  ocak ayÄ± anketi tamamlandÄ± ak parti yÃ¼kseliÅŸ trendi devam ediyor kararsÄ±zlarda anlamlÄ± bir dÃ¼ÅŸÃ¼ÅŸ var eyt toplumun   \n",
       "4                                                          benim de oynadÄ±ÄŸÄ±m futbol patronu Ä±phone oyununu bir dene   \n",
       "\n",
       "                                                                                                                            Tweet_Ceviri  \\\n",
       "0  many information and transactions related to agriculture with the mobile application in agriculture now are now a click away appstore   \n",
       "1                                                                         report the drug trade directly and fastest in the fastest way.   \n",
       "2                                                                                             smart watches do not miss for a short time   \n",
       "3                     january survey was completed, the ak party rise trend continues, there is a significant decrease in the undecided.   \n",
       "4                                                                                         try the football boss i play a game of iphone.   \n",
       "\n",
       "                                                                                             Tweet_AyrÄ±  \\\n",
       "0  many information transactions related agriculture mobile application agriculture click away appstore   \n",
       "1                                                       report drug trade directly fastest fastest way.   \n",
       "2                                                                         smart watches miss short time   \n",
       "3              january survey completed, ak party rise trend continues, significant decrease undecided.   \n",
       "4                                                                   try football boss play game iphone.   \n",
       "\n",
       "       TÃ¼r    YoÄŸunluk  \n",
       "0     NÃ¶tr   %25 - %50  \n",
       "1     NÃ¶tr   %25 - %50  \n",
       "2     NÃ¶tr   %25 - %50  \n",
       "3  Pozitif  %75 - %100  \n",
       "4  Negatif   %25 - %50  "
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Veri=pd.read_csv('textblob_eng_duygu.csv')\n",
    "Veri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "a11359cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KullanÄ±cÄ±_AdÄ±</th>\n",
       "      <th>Tweet_Tarih</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_Degistirilmis</th>\n",
       "      <th>Tweet_Ceviri</th>\n",
       "      <th>Tweet_AyrÄ±</th>\n",
       "      <th>TÃ¼r</th>\n",
       "      <th>YoÄŸunluk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Oliver Jack</td>\n",
       "      <td>2023-01-12 02:26:09+00:00</td>\n",
       "      <td>https://t.co/s8mWtQwR9G #Buca yalnÄ±z zekiyim canlÄ± ise ReÅŸat hÄ±rsÄ±zlarÄ±n</td>\n",
       "      <td>yalnÄ±z zekÃ®yim canlÄ± ise reÅŸat hÄ±rsÄ±zlarÄ±n</td>\n",
       "      <td>if i am alone, if you are alive, reÅŸat thieves</td>\n",
       "      <td>alone, alive, reÅŸat thieves</td>\n",
       "      <td>NÃ¶tr</td>\n",
       "      <td>%25 - %50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hz.Mert</td>\n",
       "      <td>2023-01-12 02:24:43+00:00</td>\n",
       "      <td>@Apple 14 Ã¼ Ã§ok baÅŸarÄ±lÄ± yapamamÄ±ÅŸsÄ±nÄ±z siz iyisi mi 15 i Ã§Ä±karÄ±n da onu alalÄ±m..</td>\n",
       "      <td>u Ã§ok baÅŸarÄ±lÄ± yapamamÄ±ÅŸsÄ±nÄ±z siz iyisi mi Ä± Ã§Ä±karÄ±n da onu alalÄ±m</td>\n",
       "      <td>you haven't done it very successful?</td>\n",
       "      <td>done successful?</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>%75 - %100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oliver Jack</td>\n",
       "      <td>2023-01-12 02:18:46+00:00</td>\n",
       "      <td>https://t.co/25IYCAwUzf #Buca bilene  yakarsÄ±n gidiyor bilirim fotograf Kitap bile degil</td>\n",
       "      <td>bilene yakarsÄ±n gidiyor bilirim fotoÄŸraf kitap bile deÄŸil</td>\n",
       "      <td>you know, i know, i know the photo is not even a book</td>\n",
       "      <td>know, know, know photo even book</td>\n",
       "      <td>NÃ¶tr</td>\n",
       "      <td>0 - 25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oliver Jack</td>\n",
       "      <td>2023-01-12 02:11:21+00:00</td>\n",
       "      <td>https://t.co/8y7hKi9J4S Gibi sigara #Buca hastaneler</td>\n",
       "      <td>gibi sigara hastaneler</td>\n",
       "      <td>cigarette hospitals like</td>\n",
       "      <td>cigarette hospitals like</td>\n",
       "      <td>NÃ¶tr</td>\n",
       "      <td>0 - 25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oliver Jack</td>\n",
       "      <td>2023-01-12 02:03:57+00:00</td>\n",
       "      <td>https://t.co/PKozS01mG2 Dinleyenler DÃ¼ÅŸÃ¼nmek daha beklemek resmen gÃ¶re Schopenhauer tohumudur #Buca bilir iyi</td>\n",
       "      <td>dinleyenler dÃ¼ÅŸÃ¼nmek daha beklemek resmen gÃ¶re schopenhauer tohumudur bilir iyi</td>\n",
       "      <td>listening to think more to wait more than the schopenhauer seed knows good.</td>\n",
       "      <td>listening think wait schopenhauer seed knows good.</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>%50 - %75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  KullanÄ±cÄ±_AdÄ±                Tweet_Tarih  \\\n",
       "5   Oliver Jack  2023-01-12 02:26:09+00:00   \n",
       "6       Hz.Mert  2023-01-12 02:24:43+00:00   \n",
       "7   Oliver Jack  2023-01-12 02:18:46+00:00   \n",
       "8   Oliver Jack  2023-01-12 02:11:21+00:00   \n",
       "9   Oliver Jack  2023-01-12 02:03:57+00:00   \n",
       "\n",
       "                                                                                                           Tweet  \\\n",
       "5                                       https://t.co/s8mWtQwR9G #Buca yalnÄ±z zekiyim canlÄ± ise ReÅŸat hÄ±rsÄ±zlarÄ±n   \n",
       "6                              @Apple 14 Ã¼ Ã§ok baÅŸarÄ±lÄ± yapamamÄ±ÅŸsÄ±nÄ±z siz iyisi mi 15 i Ã§Ä±karÄ±n da onu alalÄ±m..   \n",
       "7                       https://t.co/25IYCAwUzf #Buca bilene  yakarsÄ±n gidiyor bilirim fotograf Kitap bile degil   \n",
       "8                                                           https://t.co/8y7hKi9J4S Gibi sigara #Buca hastaneler   \n",
       "9  https://t.co/PKozS01mG2 Dinleyenler DÃ¼ÅŸÃ¼nmek daha beklemek resmen gÃ¶re Schopenhauer tohumudur #Buca bilir iyi   \n",
       "\n",
       "                                                               Tweet_Degistirilmis  \\\n",
       "5                                       yalnÄ±z zekÃ®yim canlÄ± ise reÅŸat hÄ±rsÄ±zlarÄ±n   \n",
       "6               u Ã§ok baÅŸarÄ±lÄ± yapamamÄ±ÅŸsÄ±nÄ±z siz iyisi mi Ä± Ã§Ä±karÄ±n da onu alalÄ±m   \n",
       "7                        bilene yakarsÄ±n gidiyor bilirim fotoÄŸraf kitap bile deÄŸil   \n",
       "8                                                           gibi sigara hastaneler   \n",
       "9  dinleyenler dÃ¼ÅŸÃ¼nmek daha beklemek resmen gÃ¶re schopenhauer tohumudur bilir iyi   \n",
       "\n",
       "                                                                  Tweet_Ceviri  \\\n",
       "5                               if i am alone, if you are alive, reÅŸat thieves   \n",
       "6                                         you haven't done it very successful?   \n",
       "7                        you know, i know, i know the photo is not even a book   \n",
       "8                                                     cigarette hospitals like   \n",
       "9  listening to think more to wait more than the schopenhauer seed knows good.   \n",
       "\n",
       "                                           Tweet_AyrÄ±      TÃ¼r    YoÄŸunluk  \n",
       "5                         alone, alive, reÅŸat thieves     NÃ¶tr   %25 - %50  \n",
       "6                                    done successful?  Pozitif  %75 - %100  \n",
       "7                    know, know, know photo even book     NÃ¶tr     0 - 25%  \n",
       "8                            cigarette hospitals like     NÃ¶tr     0 - 25%  \n",
       "9  listening think wait schopenhauer seed knows good.  Pozitif   %50 - %75  "
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Veri.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "a62d44e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Argo cÃ¼mle\\nmodel_path =\"martin-ha/toxic-comment-model\"\\ntokenizer=AutoTokenizer.from_pretrained(model_path)\\nmodel=AutoModelForSequenceClassification.from_pretrained(model_path)\\npipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\\ntext=\"bu cÃ¼mle toksik bir cÃ¼mle deÄŸil amÄ±nakoyayÄ±m\"\\nb_text=TextBlob(text)\\ne_text=b_text.translate(from_lang=\\'tr\\', to=\\'en\\')  \\nsonuc=pipeline(str(e_text))\\nif sonuc[0][\\'label\\']==\"toxic\":\\n    print (\"Toxic\")\\nelse:\\n    print (\"Toxic deÄŸil\")'"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Argo cÃ¼mle\n",
    "model_path =\"martin-ha/toxic-comment-model\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "pipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "text=\"bu cÃ¼mle toksik bir cÃ¼mle deÄŸil amÄ±nakoyayÄ±m\"\n",
    "b_text=TextBlob(text)\n",
    "e_text=b_text.translate(from_lang='tr', to='en')  \n",
    "sonuc=pipeline(str(e_text))\n",
    "if sonuc[0]['label']==\"toxic\":\n",
    "    print (\"Toxic\")\n",
    "else:\n",
    "    print (\"Toxic deÄŸil\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "06dea2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Cursor in module tweepy.cursor:\n",
      "\n",
      "class Cursor(builtins.object)\n",
      " |  Cursor(method, *args, **kwargs)\n",
      " |  \n",
      " |  :class:`Cursor` can be used to paginate for any :class:`API` methods that\n",
      " |  support pagination\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  method\n",
      " |      :class:`API` method to paginate for\n",
      " |  args\n",
      " |      Positional arguments to pass to ``method``\n",
      " |  kwargs\n",
      " |      Keyword arguments to pass to ``method``\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, method, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  items(self, limit=inf)\n",
      " |      Retrieve the items in each page/request\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit\n",
      " |          Maximum number of items to iterate over\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ItemIterator\n",
      " |          Iterator to iterate through items\n",
      " |  \n",
      " |  pages(self, limit=inf)\n",
      " |      Retrieve the page for each request\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit\n",
      " |          Maximum number of pages to iterate over\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      CursorIterator or DMCursorIterator or IdIterator or NextIterator or         PageIterator\n",
      " |          Iterator to iterate through pages\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tweepy.Cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "82299eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eksik CÃ¼mle\n",
    "unmasker=pipeline('fill-mask', model='xlm-roberta-base')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
