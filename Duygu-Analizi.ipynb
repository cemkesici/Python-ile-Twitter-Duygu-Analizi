{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50cb347",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install nltk\n",
    "%pip install tweepy\n",
    "%pip install pandas\n",
    "%pip install wordcloud\n",
    "%pip install textblob\n",
    "%pip install seaborn\n",
    "%pip install poyraz\n",
    "%pip install spacy\n",
    "%pip install sklearn\n",
    "%pip install zemberek-python\n",
    "%pip install trnltk\n",
    "%pip install git+https://github.com/emres/turkish-deasciifier.git\n",
    "%pip install transformers datasets\n",
    "%pip install torch\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f73c9b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cemke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*-coding:utf-8-*-\n",
    "from zemberek import (\n",
    "    TurkishSpellChecker,\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishTokenizer\n",
    ")\n",
    "import logging\n",
    "import tweepy\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "import string\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import Stream\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "from trnlp import TrnlpWord\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, TextClassificationPipeline\n",
    "from transformers import pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "31c724d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getTweets:\n",
    "    def __init__(self,ckey,csecret,atoken,asecret):\n",
    "        self.api=None\n",
    "        self.consumer_key = ckey\n",
    "        self.consumer_secret = csecret\n",
    "        self.access_token = atoken\n",
    "        self.access_token_secret = asecret\n",
    "        \n",
    "    def setAuth(self):\n",
    "        try:\n",
    "            self.auth = tweepy.OAuthHandler(self.consumer_key, self.consumer_secret)\n",
    "            self.auth.set_access_token(self.access_token, self.access_token_secret)\n",
    "            self.api = tweepy.API(self.auth)            \n",
    "            print (\"Bağlantı Yapıldı!\")                           \n",
    "        except tweepy.TweepError as err:\n",
    "            print('Error: {}'.format(err))   \n",
    "    \n",
    "    def toDataFrame(tweets):\n",
    "        try:\n",
    "            print (\"Veriler Kayıt Ediliyor...\")\n",
    "            pd.set_option('display.max_rows', None)\n",
    "            pd.set_option('display.max_columns', None)\n",
    "            pd.set_option('display.width', None)\n",
    "            pd.set_option('display.max_colwidth', None)\n",
    "            DataSet = pd.DataFrame()\n",
    "\n",
    "            DataSet['Kullanıcı_Adı'] = [tweet.user.name for tweet in tweets]\n",
    "            DataSet['Tweet_Tarih'] = [tweet.created_at for tweet in tweets]   \n",
    "            #DataSet['Tweet_Id'] = [tweet.id for tweet in tweets]\n",
    "            DataSet['Tweet'] = [tweet.text for tweet in tweets]\n",
    "            DataSet['Tweet_Degistirilmis'] = [tweet.text for tweet in tweets]\n",
    "            DataSet['Tweet_Ceviri']=[tweet.text for tweet in tweets]            \n",
    "            #DataSet['Kullanıcı_Id'] = [tweet.user.id for tweet in tweets]  \n",
    "                \n",
    "            #DataSet['Dil'] = [tweet.lang for tweet in tweets]\n",
    "            print (\"Veriler Kayıt Edildi!\")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "    \n",
    "    def searchTweet(self,aranan):\n",
    "        self.setAuth()\n",
    "        try:                      \n",
    "            print (\"Kelimeye Uygun Tweetler Sorgulanıyor...\")\n",
    "            cursor = tweepy.Cursor(self.api.search_tweets, q=aranan, result_type=\"new\", lang='tr')\n",
    "            results=[]\n",
    "            for item in cursor.items(10):\n",
    "                results.append(item)\n",
    "            print (\"Kelimeye Uygun Tweetler Sorgulandı!\")\n",
    "            DataSet = getTweets.toDataFrame(results)  \n",
    "            DataSet.to_csv('tw.csv',index=False)\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "        finally:\n",
    "            Dataset=pd.read_csv('tw.csv')                   \n",
    "            getTweets.TweetClear(DataSet)\n",
    "            getTweets.SentenceNormalization(DataSet)\n",
    "            getTweets.TweetTranslate(DataSet)\n",
    "            getTweets.KelimeAyristirma(DataSet) \n",
    "            getTweets.ToxicSentiment(DataSet)\n",
    "            getTweets.TextblobSentiment(DataSet)\n",
    "\n",
    "    def TextblobSentiment(DataSet):\n",
    "        try:\n",
    "            print (\"Duygu Analizi Yapılıyor...\")\n",
    "            Veri=DataSet\n",
    "            Veri[\"Tür\"] = Veri[\"Tweet_Ayrı\"].apply(getTweets.getPolarity)\n",
    "            Veri[\"Yoğunluk\"] = Veri[\"Tweet_Ayrı\"].apply(getTweets.getSubjectivity)\n",
    "            Veri.to_csv('textblob_eng_duygu.csv',index=False)\n",
    "            print(\"Duygu Analizi Yapıldı!\")                        \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \n",
    "            \n",
    "    \"\"\"def TrSentiment(DataSet):\n",
    "        try:\n",
    "            print(\"Türkçe Duygu Analizi Yapılıyor...\")\n",
    "            for example,index in DataSet[\"Tweet_Degistirilmis\"]:\n",
    "                DataSet[\"TR_A\"][index] = simple_token(example, sw=stopwords)\n",
    "            print(\"Türkçe Duygu Analizi Yapıldı!\")\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \"\"\"\n",
    "                     \n",
    "    def TweetTranslate(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print (\"Tweetler Çeviriliyor...\")\n",
    "            for index in range(len(data[\"Tweet_Degistirilmis\"])):\n",
    "                Ceviri_Blob=TextBlob(data[\"Tweet_Degistirilmis\"][index])\n",
    "                Eng_Blob=Ceviri_Blob.translate(from_lang='tr', to='en')  \n",
    "                data[\"Tweet_Ceviri\"][index]=Eng_Blob.lower()\n",
    "                \n",
    "            print (\"Tweetler Çevirildi!\")                      \n",
    "            return DataSet        \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def TweetClear(DataSet):\n",
    "        try:\n",
    "            print (\"Tweetler Temizleniyor...\")\n",
    "            pattern = re.compile('http[s]?://(?:[a-zA-Z0-9ğüşöçıİĞÜŞÖÇ]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F]))+|#[a-zA-Z0-9ğüşöçıİĞÜŞÖÇ]+|$[a-zA-Z0-9ğüşöçıİĞÜŞÖÇ]+|@[a-zA-Z0-9ğüşöçıİĞÜŞÖÇ_]+|[,.^_$*%-;鶯!?’\"“”:=|…#]+|\\n+|RT[\\s]+|amp[\\s]+|(^gt)')\n",
    "            for index in range(len(DataSet[\"Tweet_Degistirilmis\"])):        \n",
    "                DataSet[\"Tweet_Degistirilmis\"][index]=pattern.sub(' ', DataSet[\"Tweet_Degistirilmis\"][index])    \n",
    "                DataSet[\"Tweet_Degistirilmis\"][index]=DataSet[\"Tweet_Degistirilmis\"][index].lower()              \n",
    "            DataSet[\"Tweet_Degistirilmis\"]=DataSet[\"Tweet_Degistirilmis\"].str.replace(\"[^\\w\\s]\",\"\")\n",
    "            print (\"Tweetler Temizlendi!\")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def SentenceNormalization(DataSet):\n",
    "        try:\n",
    "            morphology = TurkishMorphology.create_with_defaults()\n",
    "            normalizer = TurkishSentenceNormalizer(morphology)\n",
    "            for data,index in DataSet[\"Tweet_Degistirilmis\"].items():\n",
    "                 DataSet[\"Tweet_Degistirilmis\"][index]= normalizer.normalize(data)\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def KelimeAyristirma(DataSet):\n",
    "        try:\n",
    "            stop = stopwords.words('english')\n",
    "            DataSet[\"Tweet_Ayrı\"] = DataSet[\"Tweet_Ceviri\"].str.split()\n",
    "            DataSet[\"Tweet_Ayrı\"] = DataSet[\"Tweet_Ayrı\"].apply(lambda x: [item for item in x if item not in stop])\n",
    "            DataSet[\"Tweet_Ayrı\"] = DataSet[\"Tweet_Ayrı\"].str.join(\" \")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "    \n",
    "    def ToxicSentiment(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print(\"Toxic Cümle Analizi Yapılıyor...\")\n",
    "            model_path =\"martin-ha/toxic-comment-model\"\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "            model=AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "            pipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "            for examples, index in data[\"Tweet_Ceviri\"].items():\n",
    "                sonuc=pipeline(str(examples))\n",
    "                if sonuc[0]['label']==\"toxic\":\n",
    "                    data[\"Tweet_Toxic\"][index]=\"Toxic\"\n",
    "                else:\n",
    "                    data[\"Tweet_Toxic\"][index]=\"Toxic değil\"    \n",
    "            print(\"Toxic Cümle Analizi Yapıldı!\")\n",
    "            return DataSet  \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "        \n",
    "    def getSubjectivity(DataSet):\n",
    "        try: \n",
    "            sub=TextBlob(DataSet).sentiment.subjectivity               \n",
    "            if sub >=0.75:\n",
    "                return \"Kesinlikle\"\n",
    "            elif sub >=0.5 and sub <0.75:\n",
    "                return \"Yüksek İhtimal\"\n",
    "            elif sub >=0.25 and sub <0.50:\n",
    "                return \"Düşük İhtimal\"\n",
    "            else:\n",
    "                return \"Kesin Değil\"\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def getPolarity(DataSet):\n",
    "        try:\n",
    "            pol=TextBlob(DataSet).sentiment.polarity\n",
    "            if pol>0.1:\n",
    "                return \"Pozitif\"\n",
    "            elif pol<-0.1:\n",
    "                return \"Negatif\"\n",
    "            else:\n",
    "                return \"Nötr\"\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "cc4db959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bağlantı Yapıldı!\n",
      "Kelimeye Uygun Tweetler Sorgulanıyor...\n",
      "Kelimeye Uygun Tweetler Sorgulandı!\n",
      "Veriler Kayıt Ediliyor...\n",
      "Veriler Kayıt Edildi!\n",
      "Tweetler Temizleniyor...\n",
      "Tweetler Temizlendi!\n",
      "2023-01-12 03:31:25,805 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 9.799805402755737\n",
      "\n",
      "Error: 'int' object has no attribute 'translate'\n",
      "Tweetler Çeviriliyor...\n",
      "Tweetler Çevirildi!\n",
      "Toxic Cümle Analizi Yapılıyor...\n",
      "Error: 'Tweet_Toxic'\n",
      "Duygu Analizi Yapılıyor...\n",
      "Duygu Analizi Yapıldı!\n"
     ]
    }
   ],
   "source": [
    "tw = getTweets( \n",
    "ckey = 'o7qidRODRWm5u07PtAWrCpSqf',\n",
    "csecret = '1Yn60OYMJl5kRCSM0XQ4Lskxh6hjM4VMz51OdsS6dM9DQuQ4MV',\n",
    "atoken = '1315792402234441730-Dt7AydgVGYI5VN9RRQfnR8Endh0WAc',\n",
    "asecret = 'jhfiDfB53Z27EqHfvfKbNdo0w2SWLqyyoAkILqgSoaGMK'\n",
    ")\n",
    "aranan=input(\"Aranacak Kelimeyi Girin: \")\n",
    "tw.searchTweet(aranan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "e018df1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kullanıcı_Adı</th>\n",
       "      <th>Tweet_Tarih</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_Degistirilmis</th>\n",
       "      <th>Tweet_Ceviri</th>\n",
       "      <th>Tweet_Ayrı</th>\n",
       "      <th>Tür</th>\n",
       "      <th>Yoğunluk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>♡🍋🍊</td>\n",
       "      <td>2023-01-11 23:54:02+00:00</td>\n",
       "      <td>RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken…</td>\n",
       "      <td>kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken</td>\n",
       "      <td>burning a bulb in his head after the enlightenment of the rice shop to offer the offer lsşskdkskcodk this child aybiken</td>\n",
       "      <td>burning bulb head enlightenment rice shop offer offer lsşskdkskcodk child aybiken</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>Kesin Değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfa</td>\n",
       "      <td>2023-01-11 23:31:22+00:00</td>\n",
       "      <td>@TamerAkyuz5 @ankara_kusu Yok edisonun bulduğu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim</td>\n",
       "      <td>yok edisonun bulduğu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim</td>\n",
       "      <td>the bulb found by the destruction of the destruction is the religion that god speaks and they are well pqzarlaşlar ed jina veinim</td>\n",
       "      <td>bulb found destruction destruction religion god speaks well pqzarlaşlar ed jina veinim</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>Kesin Değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ＥＬＡ</td>\n",
       "      <td>2023-01-11 23:20:59+00:00</td>\n",
       "      <td>RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken…</td>\n",
       "      <td>kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken</td>\n",
       "      <td>burning a bulb in his head after the enlightenment of the rice shop to offer the offer lsşskdkskcodk this child aybiken</td>\n",
       "      <td>burning bulb head enlightenment rice shop offer offer lsşskdkskcodk child aybiken</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>Kesin Değil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kullanıcı_Adı                Tweet_Tarih  \\\n",
       "0           ♡🍋🍊  2023-01-11 23:54:02+00:00   \n",
       "1          alfa  2023-01-11 23:31:22+00:00   \n",
       "2           ＥＬＡ  2023-01-11 23:20:59+00:00   \n",
       "\n",
       "                                                                                                                                          Tweet  \\\n",
       "0  RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken…   \n",
       "1                    @TamerAkyuz5 @ankara_kusu Yok edisonun bulduğu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim   \n",
       "2  RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken…   \n",
       "\n",
       "                                                                                                             Tweet_Degistirilmis  \\\n",
       "0      kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken    \n",
       "1                               yok edisonun bulduğu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim   \n",
       "2      kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken    \n",
       "\n",
       "                                                                                                                        Tweet_Ceviri  \\\n",
       "0            burning a bulb in his head after the enlightenment of the rice shop to offer the offer lsşskdkskcodk this child aybiken   \n",
       "1  the bulb found by the destruction of the destruction is the religion that god speaks and they are well pqzarlaşlar ed jina veinim   \n",
       "2            burning a bulb in his head after the enlightenment of the rice shop to offer the offer lsşskdkskcodk this child aybiken   \n",
       "\n",
       "                                                                               Tweet_Ayrı  \\\n",
       "0       burning bulb head enlightenment rice shop offer offer lsşskdkskcodk child aybiken   \n",
       "1  bulb found destruction destruction religion god speaks well pqzarlaşlar ed jina veinim   \n",
       "2       burning bulb head enlightenment rice shop offer offer lsşskdkskcodk child aybiken   \n",
       "\n",
       "    Tür     Yoğunluk  \n",
       "0  Nötr  Kesin Değil  \n",
       "1  Nötr  Kesin Değil  \n",
       "2  Nötr  Kesin Değil  "
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Veri=pd.read_csv('textblob_eng_duygu.csv')\n",
    "Veri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "a11359cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kullanıcı_Adı</th>\n",
       "      <th>Tweet_Tarih</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_Degistirilmis</th>\n",
       "      <th>Tweet_Ceviri</th>\n",
       "      <th>Tweet_Ayrı</th>\n",
       "      <th>Tür</th>\n",
       "      <th>Yoğunluk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>♡🍋🍊</td>\n",
       "      <td>2023-01-11 23:54:02+00:00</td>\n",
       "      <td>RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken…</td>\n",
       "      <td>kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken</td>\n",
       "      <td>burning a bulb in his head after the enlightenment of the rice shop to offer the offer lsşskdkskcodk this child aybiken</td>\n",
       "      <td>burning bulb head enlightenment rice shop offer offer lsşskdkskcodk child aybiken</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>Kesin Değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfa</td>\n",
       "      <td>2023-01-11 23:31:22+00:00</td>\n",
       "      <td>@TamerAkyuz5 @ankara_kusu Yok edisonun bulduğu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim</td>\n",
       "      <td>yok edisonun bulduğu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim</td>\n",
       "      <td>the bulb found by the destruction of the destruction is the religion that god speaks and they are well pqzarlaşlar ed jina veinim</td>\n",
       "      <td>bulb found destruction destruction religion god speaks well pqzarlaşlar ed jina veinim</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>Kesin Değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ＥＬＡ</td>\n",
       "      <td>2023-01-11 23:20:59+00:00</td>\n",
       "      <td>RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken…</td>\n",
       "      <td>kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken</td>\n",
       "      <td>burning a bulb in his head after the enlightenment of the rice shop to offer the offer lsşskdkskcodk this child aybiken</td>\n",
       "      <td>burning bulb head enlightenment rice shop offer offer lsşskdkskcodk child aybiken</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>Kesin Değil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kullanıcı_Adı                Tweet_Tarih  \\\n",
       "0           ♡🍋🍊  2023-01-11 23:54:02+00:00   \n",
       "1          alfa  2023-01-11 23:31:22+00:00   \n",
       "2           ＥＬＡ  2023-01-11 23:20:59+00:00   \n",
       "\n",
       "                                                                                                                                          Tweet  \\\n",
       "0  RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken…   \n",
       "1                    @TamerAkyuz5 @ankara_kusu Yok edisonun bulduğu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim   \n",
       "2  RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken…   \n",
       "\n",
       "                                                                                                             Tweet_Degistirilmis  \\\n",
       "0      kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken    \n",
       "1                               yok edisonun bulduğu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim   \n",
       "2      kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi lsşskdkskcodk bu cocuk aybiken    \n",
       "\n",
       "                                                                                                                        Tweet_Ceviri  \\\n",
       "0            burning a bulb in his head after the enlightenment of the rice shop to offer the offer lsşskdkskcodk this child aybiken   \n",
       "1  the bulb found by the destruction of the destruction is the religion that god speaks and they are well pqzarlaşlar ed jina veinim   \n",
       "2            burning a bulb in his head after the enlightenment of the rice shop to offer the offer lsşskdkskcodk this child aybiken   \n",
       "\n",
       "                                                                               Tweet_Ayrı  \\\n",
       "0       burning bulb head enlightenment rice shop offer offer lsşskdkskcodk child aybiken   \n",
       "1  bulb found destruction destruction religion god speaks well pqzarlaşlar ed jina veinim   \n",
       "2       burning bulb head enlightenment rice shop offer offer lsşskdkskcodk child aybiken   \n",
       "\n",
       "    Tür     Yoğunluk  \n",
       "0  Nötr  Kesin Değil  \n",
       "1  Nötr  Kesin Değil  \n",
       "2  Nötr  Kesin Değil  "
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Veri.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "a62d44e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Argo cümle\\nmodel_path =\"martin-ha/toxic-comment-model\"\\ntokenizer=AutoTokenizer.from_pretrained(model_path)\\nmodel=AutoModelForSequenceClassification.from_pretrained(model_path)\\npipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\\ntext=\"bu cümle toksik bir cümle değil amınakoyayım\"\\nb_text=TextBlob(text)\\ne_text=b_text.translate(from_lang=\\'tr\\', to=\\'en\\')  \\nsonuc=pipeline(str(e_text))\\nif sonuc[0][\\'label\\']==\"toxic\":\\n    print (\"Toxic\")\\nelse:\\n    print (\"Toxic değil\")'"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Argo cümle\n",
    "model_path =\"martin-ha/toxic-comment-model\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "pipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "text=\"bu cümle toksik bir cümle değil amınakoyayım\"\n",
    "b_text=TextBlob(text)\n",
    "e_text=b_text.translate(from_lang='tr', to='en')  \n",
    "sonuc=pipeline(str(e_text))\n",
    "if sonuc[0]['label']==\"toxic\":\n",
    "    print (\"Toxic\")\n",
    "else:\n",
    "    print (\"Toxic değil\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "82299eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eksik Cümle\n",
    "unmasker=pipeline('fill-mask', model='xlm-roberta-base')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
