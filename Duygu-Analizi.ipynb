{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50cb347",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in d:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tweepy in d:\\programdata\\anaconda3\\lib\\site-packages (4.12.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (2.28.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in d:\\programdata\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: wordcloud in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: matplotlib in d:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: pillow in d:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: textblob in d:\\programdata\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: joblib in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: click in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: tqdm in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in d:\\programdata\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.9.1)\n",
      "Requirement already satisfied: pandas>=0.23 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.4.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement poyraz (from versions: none)\n",
      "ERROR: No matching distribution found for poyraz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (3.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.11)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: setuptools in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: jinja2 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (8.1.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install tweepy\n",
    "%pip install pandas\n",
    "%pip install wordcloud\n",
    "%pip install textblob\n",
    "%pip install seaborn\n",
    "%pip install poyraz\n",
    "%pip install spacy\n",
    "%pip install sklearn\n",
    "%pip install zemberek-python\n",
    "%pip install trnltk\n",
    "%pip install git+https://github.com/emres/turkish-deasciifier.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f73c9b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cemke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*-coding:utf-8-*-\n",
    "from zemberek import (\n",
    "    TurkishSpellChecker,\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishTokenizer\n",
    ")\n",
    "import logging\n",
    "import tweepy\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "import string\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import Stream\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "from trnlp import TrnlpWord\n",
    "from turkish.deasciifier import Deasciifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c724d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getTweets:\n",
    "    def __init__(self,ckey,csecret,atoken,asecret):\n",
    "        self.api=None\n",
    "        self.consumer_key = ckey\n",
    "        self.consumer_secret = csecret\n",
    "        self.access_token = atoken\n",
    "        self.access_token_secret = asecret\n",
    "        \n",
    "    def setAuth(self):\n",
    "        try:\n",
    "            self.auth = tweepy.OAuthHandler(self.consumer_key, self.consumer_secret)\n",
    "            self.auth.set_access_token(self.access_token, self.access_token_secret)\n",
    "            self.api = tweepy.API(self.auth)            \n",
    "            print (\"Bağlantı Yapıldı!\")                           \n",
    "        except tweepy.TweepError as err:\n",
    "            print('Error: {}'.format(err))   \n",
    "    \n",
    "    def toDataFrame(tweets):\n",
    "        try:\n",
    "            print (\"Veriler Kayıt Ediliyor...\")\n",
    "            pd.set_option('display.max_rows', None)\n",
    "            pd.set_option('display.max_columns', None)\n",
    "            pd.set_option('display.width', None)\n",
    "            pd.set_option('display.max_colwidth', None)\n",
    "            DataSet = pd.DataFrame()\n",
    "\n",
    "            DataSet['Kullanıcı_Adı'] = [tweet.user.name for tweet in tweets]\n",
    "            DataSet['Tweet_Tarih'] = [tweet.created_at for tweet in tweets]   \n",
    "            #DataSet['Tweet_Id'] = [tweet.id for tweet in tweets]\n",
    "            DataSet['Tweet'] = [tweet.text for tweet in tweets]\n",
    "            DataSet['Tweet_Degistirilmis'] = [tweet.text for tweet in tweets]\n",
    "            DataSet['Tweet_Ceviri']=[tweet.text for tweet in tweets]            \n",
    "            #DataSet['Kullanıcı_Id'] = [tweet.user.id for tweet in tweets]  \n",
    "                \n",
    "            #DataSet['Dil'] = [tweet.lang for tweet in tweets]\n",
    "            print (\"Veriler Kayıt Edildi!\")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "    \n",
    "    def searchTweet(self,aranan):\n",
    "        self.setAuth()\n",
    "        try:                      \n",
    "            print (\"Kelimeye Uygun Tweetler Sorgulanıyor...\")\n",
    "            cursor = tweepy.Cursor(self.api.search_tweets, q=aranan, result_type=\"new\", lang='tr')\n",
    "            results=[]\n",
    "            for item in cursor.items(10):\n",
    "                results.append(item)\n",
    "            print (\"Kelimeye Uygun Tweetler Sorgulandı!\")\n",
    "            DataSet = getTweets.toDataFrame(results)  \n",
    "            getTweets.TweetClear(DataSet)\n",
    "            getTweets.SentenceNormalization(DataSet)\n",
    "            getTweets.TweetTranslate(DataSet)\n",
    "            getTweets.KelimeAyristirma(DataSet) \n",
    "            DataSet.to_csv('tw.csv',index=False)\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "        finally:\n",
    "            getTweets.TextblobSentiment(DataSet)\n",
    "\n",
    "    def TextblobSentiment(DataSet):\n",
    "        try:\n",
    "            print (\"Duygu Analizi Yapılıyor...\")\n",
    "            Veri=DataSet\n",
    "            Veri[\"Tür\"] = Veri[\"Tweet_Ayrı\"].apply(getTweets.getPolarity)\n",
    "            Veri[\"Yoğunluk\"] = Veri[\"Tweet_Ayrı\"].apply(getTweets.getSubjectivity)\n",
    "            Veri.to_csv('textblob_eng_duygu.csv',index=False)\n",
    "            print(\"Duygu Analizi Yapıldı!\")                        \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \n",
    "            \n",
    "    \"\"\"def TrSentiment(DataSet):\n",
    "        try:\n",
    "            print(\"Türkçe Duygu Analizi Yapılıyor...\")\n",
    "            for example,index in DataSet[\"Tweet_Degistirilmis\"]:\n",
    "                DataSet[\"TR_A\"][index] = simple_token(example, sw=stopwords)\n",
    "            print(\"Türkçe Duygu Analizi Yapıldı!\")\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \"\"\"\n",
    "                     \n",
    "    def TweetTranslate(DataSet):\n",
    "        try:\n",
    "            print (\"Tweetler Çeviriliyor...\")\n",
    "            for yazi in range(len(DataSet[\"Tweet_Degistirilmis\"])):\n",
    "                Ceviri_Blob=TextBlob(DataSet[\"Tweet_Degistirilmis\"][yazi])\n",
    "                Eng_Blob=Ceviri_Blob.translate(from_lang='tr', to='en')  \n",
    "                DataSet[\"Tweet_Ceviri\"][yazi]=Eng_Blob\n",
    "                DataSet[\"Tweet_Ceviri\"][yazi]=DataSet[\"Tweet_Ceviri\"][yazi].lower()\n",
    "            print (\"Tweetler Çevirildi!\")                      \n",
    "            return DataSet        \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def TweetClear(DataSet):\n",
    "        try:\n",
    "            print (\"Tweetler Temizleniyor...\")\n",
    "            pattern = re.compile('http[s]?://(?:[A-Za-z0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+|#[A-Za-z0-9]+|$[A-Za-z0-9]+|@[A-Za-z0-9_]+|[,.^_$*%-;鶯!?’\"“”:=|…]+|\\n+|RT+|&amp')\n",
    "            for i in range(len(DataSet[\"Tweet_Degistirilmis\"])):        \n",
    "                DataSet[\"Tweet_Degistirilmis\"][i]=pattern.sub('', DataSet[\"Tweet_Degistirilmis\"][i])    \n",
    "                DataSet[\"Tweet_Degistirilmis\"][i]=DataSet[\"Tweet_Degistirilmis\"][i].lower()              \n",
    "            DataSet[\"Tweet_Degistirilmis\"]=DataSet[\"Tweet_Degistirilmis\"].str.replace(\"[^\\w\\s]\",\"\")\n",
    "            print (\"Tweetler Temizlendi!\")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def SentenceNormalization(DataSet):\n",
    "        try:\n",
    "            morphology = TurkishMorphology.create_with_defaults()\n",
    "            normalizer = TurkishSentenceNormalizer(morphology)\n",
    "\n",
    "            start = time.time()\n",
    "            for example,index in DataSet[\"Tweet_Degistirilmis\"]:\n",
    "                 DataSet[\"Tweet_Degistirilmis\"][index]= normalizer.normalize(example)\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def KelimeAyristirma(DataSet):\n",
    "        try:\n",
    "            stop = stopwords.words('english')\n",
    "            DataSet[\"Tweet_Ayrı\"] = DataSet[\"Tweet_Ceviri\"].str.split()\n",
    "            DataSet[\"Tweet_Ayrı\"] = DataSet[\"Tweet_Ayrı\"].apply(lambda x: [item for item in x if item not in stop])\n",
    "            DataSet[\"Tweet_Ayrı\"] = DataSet[\"Tweet_Ayrı\"].str.join(\" \")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "        \n",
    "    def getSubjectivity(DataSet):\n",
    "        try: \n",
    "            sub=TextBlob(DataSet).sentiment.subjectivity               \n",
    "            if sub >=0.75:\n",
    "                return \"Kesinlikle\"\n",
    "            elif sub >=0.5 and sub <0.75:\n",
    "                return \"Yüksek İhtimal\"\n",
    "            elif sub >=0.25 and sub <0.50:\n",
    "                return \"Düşük İhtimal\"\n",
    "            else:\n",
    "                return \"Kesin Değil\"\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def getPolarity(DataSet):\n",
    "        try:\n",
    "            pol=TextBlob(DataSet).sentiment.polarity\n",
    "            if pol>0.1:\n",
    "                return \"Pozitif\"\n",
    "            elif pol<-0.1:\n",
    "                return \"Negatif\"\n",
    "            else:\n",
    "                return \"Nötr\"\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc4db959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bağlantı Yapıldı!\n",
      "Kelimeye Uygun Tweetler Sorgulanıyor...\n",
      "Kelimeye Uygun Tweetler Sorgulandı!\n",
      "Veriler Kayıt Ediliyor...\n",
      "Veriler Kayıt Edildi!\n",
      "Tweetler Temizleniyor...\n",
      "Tweetler Temizlendi!\n",
      "2023-01-10 03:16:22,120 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 8.251937627792358\n",
      "\n",
      "Error: too many values to unpack (expected 2)\n",
      "Tweetler Çeviriliyor...\n",
      "Tweetler Çevirildi!\n",
      "Duygu Analizi Yapılıyor...\n",
      "Duygu Analizi Yapıldı!\n"
     ]
    }
   ],
   "source": [
    "tw = getTweets( \n",
    "ckey = 'o7qidRODRWm5u07PtAWrCpSqf',\n",
    "csecret = '1Yn60OYMJl5kRCSM0XQ4Lskxh6hjM4VMz51OdsS6dM9DQuQ4MV',\n",
    "atoken = '1315792402234441730-Dt7AydgVGYI5VN9RRQfnR8Endh0WAc',\n",
    "asecret = 'jhfiDfB53Z27EqHfvfKbNdo0w2SWLqyyoAkILqgSoaGMK'\n",
    ")\n",
    "aranan=input(\"Aranacak Kelimeyi Girin: \")\n",
    "tw.searchTweet(aranan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e018df1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kullanıcı_Adı</th>\n",
       "      <th>Tweet_Tarih</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_Degistirilmis</th>\n",
       "      <th>Tweet_Ceviri</th>\n",
       "      <th>Tweet_Ayrı</th>\n",
       "      <th>Tür</th>\n",
       "      <th>Yoğunluk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janel 📖</td>\n",
       "      <td>2023-01-10 00:16:10+00:00</td>\n",
       "      <td>269343888 defneyaprağıacaktım etyaranacaklar kara sabanacaklar glütenecektim gücendiriciecektim formülleştirmekebil… https://t.co/sJmsMsJtED</td>\n",
       "      <td>defneyaprağıacaktım etyaranacaklar kara sabanacaklar glütenecektim gücendiriciecektim formülleştirmekebil</td>\n",
       "      <td>i was going to laurel.</td>\n",
       "      <td>going laurel.</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>Kesin Değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEHMET AKIF DEMIR</td>\n",
       "      <td>2023-01-10 00:15:22+00:00</td>\n",
       "      <td>@bbcturkce Ozon delindi diyorlar tamam! Ozon yama tuttu diyorlar tamam!Kara delik keşfettik diyorlar tamam! Uzayın… https://t.co/LOJh18iSsY</td>\n",
       "      <td>ozon delindi diyorlar tamam ozon yama tuttu diyorlar tamamkara delik keşfettik diyorlar tamam uzayın</td>\n",
       "      <td>they say ozone is punctured, they say ozone kept patch.</td>\n",
       "      <td>say ozone punctured, say ozone kept patch.</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>Kesin Değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hakan Kanat خاقان قناد</td>\n",
       "      <td>2023-01-10 00:14:29+00:00</td>\n",
       "      <td>RT @baarrss__: Bu işler böyledir; Halep demezseniz Hatay’ı tartışmaya açarlar, Musul-Kerkük demezseniz Diyarbakır’a göz koyarlar, Selanik d…</td>\n",
       "      <td>bu işler böyledir halep demezseniz hatayı tartışmaya açarlar musulkerkük demezseniz diyarbakıra göz koyarlar selanik d</td>\n",
       "      <td>if you do not say aleppo, they will open the mistake if you don't say mosulkerkuk, they put an eye on diyarbakır.</td>\n",
       "      <td>say aleppo, open mistake say mosulkerkuk, put eye diyarbakır.</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>Yüksek İhtimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ŞAH-I MERDAN</td>\n",
       "      <td>2023-01-10 00:14:24+00:00</td>\n",
       "      <td>RT @KarasoyMurad: Kıymetli Dostlar,\\nyurtdışına çıkmak isterken açılan ateş sonrası vefat eden KHK’lının, faşist iktidarın kara propaganda a…</td>\n",
       "      <td>kıymetli dostlaryurtdışına çıkmak isterken açılan ateş sonrası vefat eden khklının faşist iktidarın kara propaganda a</td>\n",
       "      <td>dear friends who died after the fire opened while trying to go to the fascist power of the black propaganda a</td>\n",
       "      <td>dear friends died fire opened trying go fascist power black propaganda</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Düşük İhtimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...</td>\n",
       "      <td>2023-01-10 00:13:56+00:00</td>\n",
       "      <td>Seni çok seviyorum n'e'fesim. 🖤\\nBiliyorum hep benimlesin..\\nGülüşün, bakışların, kokun, nefesin..\\nBu acı hiç geçmedi… https://t.co/pIR2WJVxb5</td>\n",
       "      <td>seni çok seviyorum nefesim biliyorum hep benimlesingülüşün bakışların kokun nefesinbu acı hiç geçmedi</td>\n",
       "      <td>i love you so much, i know my breath, your gaze is always your breath, your breath has never passed</td>\n",
       "      <td>love much, know breath, gaze always breath, breath never passed</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>Düşük İhtimal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Kullanıcı_Adı                Tweet_Tarih  \\\n",
       "0                 Janel 📖  2023-01-10 00:16:10+00:00   \n",
       "1       MEHMET AKIF DEMIR  2023-01-10 00:15:22+00:00   \n",
       "2  Hakan Kanat خاقان قناد  2023-01-10 00:14:29+00:00   \n",
       "3            ŞAH-I MERDAN  2023-01-10 00:14:24+00:00   \n",
       "4                     ...  2023-01-10 00:13:56+00:00   \n",
       "\n",
       "                                                                                                                                             Tweet  \\\n",
       "0     269343888 defneyaprağıacaktım etyaranacaklar kara sabanacaklar glütenecektim gücendiriciecektim formülleştirmekebil… https://t.co/sJmsMsJtED   \n",
       "1      @bbcturkce Ozon delindi diyorlar tamam! Ozon yama tuttu diyorlar tamam!Kara delik keşfettik diyorlar tamam! Uzayın… https://t.co/LOJh18iSsY   \n",
       "2     RT @baarrss__: Bu işler böyledir; Halep demezseniz Hatay’ı tartışmaya açarlar, Musul-Kerkük demezseniz Diyarbakır’a göz koyarlar, Selanik d…   \n",
       "3    RT @KarasoyMurad: Kıymetli Dostlar,\\nyurtdışına çıkmak isterken açılan ateş sonrası vefat eden KHK’lının, faşist iktidarın kara propaganda a…   \n",
       "4  Seni çok seviyorum n'e'fesim. 🖤\\nBiliyorum hep benimlesin..\\nGülüşün, bakışların, kokun, nefesin..\\nBu acı hiç geçmedi… https://t.co/pIR2WJVxb5   \n",
       "\n",
       "                                                                                                        Tweet_Degistirilmis  \\\n",
       "0                defneyaprağıacaktım etyaranacaklar kara sabanacaklar glütenecektim gücendiriciecektim formülleştirmekebil    \n",
       "1                     ozon delindi diyorlar tamam ozon yama tuttu diyorlar tamamkara delik keşfettik diyorlar tamam uzayın    \n",
       "2    bu işler böyledir halep demezseniz hatayı tartışmaya açarlar musulkerkük demezseniz diyarbakıra göz koyarlar selanik d   \n",
       "3     kıymetli dostlaryurtdışına çıkmak isterken açılan ateş sonrası vefat eden khklının faşist iktidarın kara propaganda a   \n",
       "4                    seni çok seviyorum nefesim biliyorum hep benimlesingülüşün bakışların kokun nefesinbu acı hiç geçmedi    \n",
       "\n",
       "                                                                                                        Tweet_Ceviri  \\\n",
       "0                                                                                             i was going to laurel.   \n",
       "1                                                            they say ozone is punctured, they say ozone kept patch.   \n",
       "2  if you do not say aleppo, they will open the mistake if you don't say mosulkerkuk, they put an eye on diyarbakır.   \n",
       "3      dear friends who died after the fire opened while trying to go to the fascist power of the black propaganda a   \n",
       "4                i love you so much, i know my breath, your gaze is always your breath, your breath has never passed   \n",
       "\n",
       "                                                               Tweet_Ayrı  \\\n",
       "0                                                           going laurel.   \n",
       "1                              say ozone punctured, say ozone kept patch.   \n",
       "2           say aleppo, open mistake say mosulkerkuk, put eye diyarbakır.   \n",
       "3  dear friends died fire opened trying go fascist power black propaganda   \n",
       "4         love much, know breath, gaze always breath, breath never passed   \n",
       "\n",
       "       Tür        Yoğunluk  \n",
       "0     Nötr     Kesin Değil  \n",
       "1     Nötr     Kesin Değil  \n",
       "2     Nötr  Yüksek İhtimal  \n",
       "3  Negatif   Düşük İhtimal  \n",
       "4  Pozitif   Düşük İhtimal  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Veri=pd.read_csv('textblob_eng_duygu.csv')\n",
    "Veri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2020640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kullanıcı_Adı</th>\n",
       "      <th>Tweet_Tarih</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_Degistirilmis</th>\n",
       "      <th>Tweet_Ceviri</th>\n",
       "      <th>Tweet_Ayrı</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janel 📖</td>\n",
       "      <td>2023-01-10 00:16:10+00:00</td>\n",
       "      <td>269343888 defneyaprağıacaktım etyaranacaklar kara sabanacaklar glütenecektim gücendiriciecektim formülleştirmekebil… https://t.co/sJmsMsJtED</td>\n",
       "      <td>defneyaprağıacaktım etyaranacaklar kara sabanacaklar glütenecektim gücendiriciecektim formülleştirmekebil</td>\n",
       "      <td>i was going to laurel.</td>\n",
       "      <td>going laurel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEHMET AKIF DEMIR</td>\n",
       "      <td>2023-01-10 00:15:22+00:00</td>\n",
       "      <td>@bbcturkce Ozon delindi diyorlar tamam! Ozon yama tuttu diyorlar tamam!Kara delik keşfettik diyorlar tamam! Uzayın… https://t.co/LOJh18iSsY</td>\n",
       "      <td>ozon delindi diyorlar tamam ozon yama tuttu diyorlar tamamkara delik keşfettik diyorlar tamam uzayın</td>\n",
       "      <td>they say ozone is punctured, they say ozone kept patch.</td>\n",
       "      <td>say ozone punctured, say ozone kept patch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hakan Kanat خاقان قناد</td>\n",
       "      <td>2023-01-10 00:14:29+00:00</td>\n",
       "      <td>RT @baarrss__: Bu işler böyledir; Halep demezseniz Hatay’ı tartışmaya açarlar, Musul-Kerkük demezseniz Diyarbakır’a göz koyarlar, Selanik d…</td>\n",
       "      <td>bu işler böyledir halep demezseniz hatayı tartışmaya açarlar musulkerkük demezseniz diyarbakıra göz koyarlar selanik d</td>\n",
       "      <td>if you do not say aleppo, they will open the mistake if you don't say mosulkerkuk, they put an eye on diyarbakır.</td>\n",
       "      <td>say aleppo, open mistake say mosulkerkuk, put eye diyarbakır.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ŞAH-I MERDAN</td>\n",
       "      <td>2023-01-10 00:14:24+00:00</td>\n",
       "      <td>RT @KarasoyMurad: Kıymetli Dostlar,\\nyurtdışına çıkmak isterken açılan ateş sonrası vefat eden KHK’lının, faşist iktidarın kara propaganda a…</td>\n",
       "      <td>kıymetli dostlaryurtdışına çıkmak isterken açılan ateş sonrası vefat eden khklının faşist iktidarın kara propaganda a</td>\n",
       "      <td>dear friends who died after the fire opened while trying to go to the fascist power of the black propaganda a</td>\n",
       "      <td>dear friends died fire opened trying go fascist power black propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...</td>\n",
       "      <td>2023-01-10 00:13:56+00:00</td>\n",
       "      <td>Seni çok seviyorum n'e'fesim. 🖤\\nBiliyorum hep benimlesin..\\nGülüşün, bakışların, kokun, nefesin..\\nBu acı hiç geçmedi… https://t.co/pIR2WJVxb5</td>\n",
       "      <td>seni çok seviyorum nefesim biliyorum hep benimlesingülüşün bakışların kokun nefesinbu acı hiç geçmedi</td>\n",
       "      <td>i love you so much, i know my breath, your gaze is always your breath, your breath has never passed</td>\n",
       "      <td>love much, know breath, gaze always breath, breath never passed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Kullanıcı_Adı                Tweet_Tarih  \\\n",
       "0                 Janel 📖  2023-01-10 00:16:10+00:00   \n",
       "1       MEHMET AKIF DEMIR  2023-01-10 00:15:22+00:00   \n",
       "2  Hakan Kanat خاقان قناد  2023-01-10 00:14:29+00:00   \n",
       "3            ŞAH-I MERDAN  2023-01-10 00:14:24+00:00   \n",
       "4                     ...  2023-01-10 00:13:56+00:00   \n",
       "\n",
       "                                                                                                                                             Tweet  \\\n",
       "0     269343888 defneyaprağıacaktım etyaranacaklar kara sabanacaklar glütenecektim gücendiriciecektim formülleştirmekebil… https://t.co/sJmsMsJtED   \n",
       "1      @bbcturkce Ozon delindi diyorlar tamam! Ozon yama tuttu diyorlar tamam!Kara delik keşfettik diyorlar tamam! Uzayın… https://t.co/LOJh18iSsY   \n",
       "2     RT @baarrss__: Bu işler böyledir; Halep demezseniz Hatay’ı tartışmaya açarlar, Musul-Kerkük demezseniz Diyarbakır’a göz koyarlar, Selanik d…   \n",
       "3    RT @KarasoyMurad: Kıymetli Dostlar,\\nyurtdışına çıkmak isterken açılan ateş sonrası vefat eden KHK’lının, faşist iktidarın kara propaganda a…   \n",
       "4  Seni çok seviyorum n'e'fesim. 🖤\\nBiliyorum hep benimlesin..\\nGülüşün, bakışların, kokun, nefesin..\\nBu acı hiç geçmedi… https://t.co/pIR2WJVxb5   \n",
       "\n",
       "                                                                                                        Tweet_Degistirilmis  \\\n",
       "0                defneyaprağıacaktım etyaranacaklar kara sabanacaklar glütenecektim gücendiriciecektim formülleştirmekebil    \n",
       "1                     ozon delindi diyorlar tamam ozon yama tuttu diyorlar tamamkara delik keşfettik diyorlar tamam uzayın    \n",
       "2    bu işler böyledir halep demezseniz hatayı tartışmaya açarlar musulkerkük demezseniz diyarbakıra göz koyarlar selanik d   \n",
       "3     kıymetli dostlaryurtdışına çıkmak isterken açılan ateş sonrası vefat eden khklının faşist iktidarın kara propaganda a   \n",
       "4                    seni çok seviyorum nefesim biliyorum hep benimlesingülüşün bakışların kokun nefesinbu acı hiç geçmedi    \n",
       "\n",
       "                                                                                                        Tweet_Ceviri  \\\n",
       "0                                                                                             i was going to laurel.   \n",
       "1                                                            they say ozone is punctured, they say ozone kept patch.   \n",
       "2  if you do not say aleppo, they will open the mistake if you don't say mosulkerkuk, they put an eye on diyarbakır.   \n",
       "3      dear friends who died after the fire opened while trying to go to the fascist power of the black propaganda a   \n",
       "4                i love you so much, i know my breath, your gaze is always your breath, your breath has never passed   \n",
       "\n",
       "                                                               Tweet_Ayrı  \n",
       "0                                                           going laurel.  \n",
       "1                              say ozone punctured, say ozone kept patch.  \n",
       "2           say aleppo, open mistake say mosulkerkuk, put eye diyarbakır.  \n",
       "3  dear friends died fire opened trying go fascist power black propaganda  \n",
       "4         love much, know breath, gaze always breath, breath never passed  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Veri1=pd.read_csv('tw.csv')\n",
    "Veri1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62d44e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
