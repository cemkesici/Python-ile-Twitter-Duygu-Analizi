{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "e50cb347",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: nltk in d:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tweepy in d:\\programdata\\anaconda3\\lib\\site-packages (4.12.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (2.28.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in d:\\programdata\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wordcloud in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: pillow in d:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: matplotlib in d:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in d:\\programdata\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: click in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in d:\\programdata\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.4.4)\n",
      "Requirement already satisfied: scipy>=1.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.9.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement poyraz (from versions: none)\n",
      "ERROR: No matching distribution found for poyraz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (3.4.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: setuptools in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.11)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (8.1.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (0.0.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: zemberek-python in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (0.2.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from zemberek-python) (1.21.5)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from zemberek-python) (4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: trnltk in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (0.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/emres/turkish-deasciifier.git\n",
      "  Cloning https://github.com/emres/turkish-deasciifier.git to c:\\users\\cemke\\appdata\\local\\temp\\pip-req-build-2fi4_6eh\n",
      "  Resolved https://github.com/emres/turkish-deasciifier.git to commit 665154c734b09485c3d11ce0038cd121dd109594\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/emres/turkish-deasciifier.git 'C:\\Users\\cemke\\AppData\\Local\\Temp\\pip-req-build-2fi4_6eh'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (4.25.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (2.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: dill<0.3.7 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pandas in d:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: packaging in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.29.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\cemke\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install tweepy\n",
    "%pip install pandas\n",
    "%pip install wordcloud\n",
    "%pip install textblob\n",
    "%pip install seaborn\n",
    "%pip install poyraz\n",
    "%pip install spacy\n",
    "%pip install sklearn\n",
    "%pip install zemberek-python\n",
    "%pip install trnltk\n",
    "%pip install git+https://github.com/emres/turkish-deasciifier.git\n",
    "%pip install transformers datasets\n",
    "%pip install torch\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "f73c9b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cemke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*-coding:utf-8-*-\n",
    "from zemberek import (\n",
    "    TurkishSpellChecker,\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishTokenizer\n",
    ")\n",
    "import logging\n",
    "import tweepy\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "import string\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import Stream\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "from trnlp import TrnlpWord\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, TextClassificationPipeline\n",
    "from transformers import pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "31c724d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getTweets:\n",
    "    def __init__(self,ckey,csecret,atoken,asecret):\n",
    "        self.api=None\n",
    "        self.consumer_key = ckey\n",
    "        self.consumer_secret = csecret\n",
    "        self.access_token = atoken\n",
    "        self.access_token_secret = asecret\n",
    "        \n",
    "    def setAuth(self):\n",
    "        try:\n",
    "            self.auth = tweepy.OAuthHandler(self.consumer_key, self.consumer_secret)\n",
    "            self.auth.set_access_token(self.access_token, self.access_token_secret)\n",
    "            self.api = tweepy.API(self.auth)            \n",
    "            print (\"Bağlantı Yapıldı!\")                           \n",
    "        except tweepy.TweepError as err:\n",
    "            print('Error: {}'.format(err))   \n",
    "    \n",
    "    def toDataFrame(tweets):\n",
    "        try:\n",
    "            print (\"Veriler Kayıt Ediliyor...\")\n",
    "            pd.set_option('display.max_rows', None)\n",
    "            pd.set_option('display.max_columns', None)\n",
    "            pd.set_option('display.width', None)\n",
    "            pd.set_option('display.max_colwidth', None)\n",
    "            DataSet = pd.DataFrame()\n",
    "\n",
    "            DataSet['Kullanıcı_Adı'] = [tweet.user.name for tweet in tweets]\n",
    "            DataSet['Tweet_Tarih'] = [tweet.created_at for tweet in tweets]   \n",
    "            #DataSet['Tweet_Id'] = [tweet.id for tweet in tweets]\n",
    "            DataSet['Tweet'] = [tweet.text for tweet in tweets]\n",
    "            DataSet['Tweet_Degistirilmis'] = [tweet.text for tweet in tweets]\n",
    "            DataSet['Tweet_Ceviri']=[tweet.text for tweet in tweets]            \n",
    "            #DataSet['Kullanıcı_Id'] = [tweet.user.id for tweet in tweets]  \n",
    "                \n",
    "            #DataSet['Dil'] = [tweet.lang for tweet in tweets]\n",
    "            print (\"Veriler Kayıt Edildi!\")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "    \n",
    "    def searchTweet(self,aranan):\n",
    "        self.setAuth()\n",
    "        try:                      \n",
    "            print (\"Kelimeye Uygun Tweetler Sorgulanıyor...\")\n",
    "            cursor = tweepy.Cursor(self.api.search_tweets, q=aranan, result_type=\"mixed\", lang='tr')\n",
    "            results=[]\n",
    "            for item in cursor.items(10):\n",
    "                results.append(item)\n",
    "            print (\"Kelimeye Uygun Tweetler Sorgulandı!\")\n",
    "            DataSet = getTweets.toDataFrame(results)  \n",
    "            DataSet.to_csv('tw.csv')\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "        finally:\n",
    "            Dataset=pd.read_csv('tw.csv')                   \n",
    "            getTweets.TweetClear(DataSet)\n",
    "            getTweets.SentenceNormalization(DataSet)\n",
    "            getTweets.TweetTranslate(DataSet)\n",
    "            getTweets.KelimeAyristirma(DataSet) \n",
    "            getTweets.ToxicSentiment(DataSet)\n",
    "            getTweets.TextblobSentiment(DataSet)\n",
    "\n",
    "    def TextblobSentiment(DataSet):\n",
    "        try:\n",
    "            print (\"Duygu Analizi Yapılıyor...\")\n",
    "            Veri=DataSet\n",
    "            Veri[\"Tür\"] = Veri[\"Tweet_Ayrı\"].apply(getTweets.getPolarity)\n",
    "            Veri[\"Yoğunluk\"] = Veri[\"Tweet_Ayrı\"].apply(getTweets.getSubjectivity)\n",
    "            Veri.to_csv('textblob_eng_duygu.csv',index=False)\n",
    "            print(\"Duygu Analizi Yapıldı!\")                        \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \n",
    "            \n",
    "    \"\"\"def TrSentiment(DataSet):\n",
    "        try:\n",
    "            print(\"Türkçe Duygu Analizi Yapılıyor...\")\n",
    "            for example,index in DataSet[\"Tweet_Degistirilmis\"]:\n",
    "                DataSet[\"TR_A\"][index] = simple_token(example, sw=stopwords)\n",
    "            print(\"Türkçe Duygu Analizi Yapıldı!\")\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \"\"\"\n",
    "    def TweetClear(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print (\"Tweetler Temizleniyor...\")\n",
    "            pattern = re.compile('http[s]?://(?:[a-zA-Z0-9ğüşöçıİĞÜŞÖÇ]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F]))+|#[a-zA-Z0-9ğüşöçıİĞÜŞÖÇ]+|$[a-zA-ZğüşöçıİĞÜŞÖÇ]+|@[a-zA-Z0-9ğüşöçıİĞÜŞÖÇ_]+|[,.^_$*%-;鶯!?’\"“”:=|…#]+|\\n+|RT[\\s]+|amp[\\s]+|(^gt)')\n",
    "            for index in range(len(data[\"Tweet_Degistirilmis\"])):        \n",
    "                data[\"Tweet_Degistirilmis\"][index]=pattern.sub(' ', data[\"Tweet_Degistirilmis\"][index])    \n",
    "                data[\"Tweet_Degistirilmis\"][index]=data[\"Tweet_Degistirilmis\"][index].lower()              \n",
    "            data[\"Tweet_Degistirilmis\"]=data[\"Tweet_Degistirilmis\"].str.replace(\"[^\\w\\s]\",\"\")\n",
    "            print (\"Tweetler Temizlendi!\")\n",
    "            return data\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))  \n",
    "                              \n",
    "    def TweetTranslate(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print (\"Tweetler Çeviriliyor...\")\n",
    "            for index in range(len(data[\"Tweet_Degistirilmis\"])):\n",
    "                Ceviri_Blob=TextBlob(data[\"Tweet_Degistirilmis\"][index])\n",
    "                Eng_Blob=Ceviri_Blob.translate(from_lang='tr', to='en')  \n",
    "                data[\"Tweet_Ceviri\"][index]=Eng_Blob.lower()                \n",
    "            print (\"Tweetler Çevirildi!\")                      \n",
    "            return data        \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \n",
    "            \n",
    "    def SentenceNormalization(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print(\"Cümle Normalizasyonu Yapılıyor...\")\n",
    "            logger = logging.getLogger(__name__)            \n",
    "            morphology = TurkishMorphology.create_with_defaults()\n",
    "            normalizer = TurkishSentenceNormalizer(morphology)\n",
    "            for index in range(len(data[\"Tweet_Degistirilmis\"])):                \n",
    "                data[\"Tweet_Degistirilmis\"][index]= normalizer.normalize(data[\"Tweet_Degistirilmis\"][index])\n",
    "            print(\"Cümle Normalizasyonu Yapıldı!\")\n",
    "            sc = TurkishSpellChecker(morphology)\n",
    "            return data\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def KelimeAyristirma(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            stop = stopwords.words('english')\n",
    "            data[\"Tweet_Ayrı\"] = data[\"Tweet_Ceviri\"].str.split()\n",
    "            data[\"Tweet_Ayrı\"] = data[\"Tweet_Ayrı\"].apply(lambda x: [item for item in x if item not in stop])\n",
    "            data[\"Tweet_Ayrı\"] = data[\"Tweet_Ayrı\"].str.join(\" \")\n",
    "            return data\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "    \n",
    "    def ToxicSentiment(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print(\"Toxic Cümle Analizi Yapılıyor...\")\n",
    "            model_path =\"martin-ha/toxic-comment-model\"\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "            model=AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "            pipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "            for index in range(len(data[\"Tweet_Ceviri\"])):\n",
    "                sonuc=pipeline(str(data[\"Tweet_Toxic\"][index]))\n",
    "                if sonuc[0]['label']==\"toxic\":\n",
    "                    data[\"Tweet_Toxic\"][index]=\"Toxic\"\n",
    "                else:\n",
    "                    data[\"Tweet_Toxic\"][index]=\"Toxic değil\"    \n",
    "            print(\"Toxic Cümle Analizi Yapıldı!\")\n",
    "            return data  \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "        \n",
    "    def getSubjectivity(DataSet):\n",
    "        try: \n",
    "            sub=TextBlob(DataSet).sentiment.subjectivity               \n",
    "            if sub >=0.75:\n",
    "                return \"%75 - %100\"\n",
    "            elif sub >=0.5 and sub <0.75:\n",
    "                return \"%50 - %75\"\n",
    "            elif sub >=0.25 and sub <0.50:\n",
    "                return \"%25 - %50\"\n",
    "            else:\n",
    "                return \"0 - 25%\"\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def getPolarity(DataSet):\n",
    "        try:\n",
    "            pol=TextBlob(DataSet).sentiment.polarity\n",
    "            if pol>0.3:\n",
    "                return \"Pozitif\"\n",
    "            elif pol<-0.3:\n",
    "                return \"Negatif\"\n",
    "            else:\n",
    "                return \"Nötr\"\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "cc4db959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bağlantı Yapıldı!\n",
      "Kelimeye Uygun Tweetler Sorgulanıyor...\n",
      "Kelimeye Uygun Tweetler Sorgulandı!\n",
      "Veriler Kayıt Ediliyor...\n",
      "Veriler Kayıt Edildi!\n",
      "Tweetler Temizleniyor...\n",
      "Tweetler Temizlendi!\n",
      "Cümle Normalizasyonu Yapılıyor...\n",
      "2023-01-12 05:30:10,185 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 9.684077739715576\n",
      "\n",
      "Cümle Normalizasyonu Yapıldı!\n",
      "Tweetler Çeviriliyor...\n",
      "Tweetler Çevirildi!\n",
      "Toxic Cümle Analizi Yapılıyor...\n",
      "Error: 'Tweet_Toxic'\n",
      "Duygu Analizi Yapılıyor...\n",
      "Duygu Analizi Yapıldı!\n"
     ]
    }
   ],
   "source": [
    "tw = getTweets( \n",
    "ckey = 'o7qidRODRWm5u07PtAWrCpSqf',\n",
    "csecret = '1Yn60OYMJl5kRCSM0XQ4Lskxh6hjM4VMz51OdsS6dM9DQuQ4MV',\n",
    "atoken = '1315792402234441730-Dt7AydgVGYI5VN9RRQfnR8Endh0WAc',\n",
    "asecret = 'jhfiDfB53Z27EqHfvfKbNdo0w2SWLqyyoAkILqgSoaGMK'\n",
    ")\n",
    "aranan=input(\"Aranacak Kelimeyi Girin: \")\n",
    "tw.searchTweet(aranan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "e018df1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kullanıcı_Adı</th>\n",
       "      <th>Tweet_Tarih</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_Degistirilmis</th>\n",
       "      <th>Tweet_Ceviri</th>\n",
       "      <th>Tweet_Ayrı</th>\n",
       "      <th>Tür</th>\n",
       "      <th>Yoğunluk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T.C. Tarım ve Orman Bakanlığı</td>\n",
       "      <td>2023-01-02 13:23:39+00:00</td>\n",
       "      <td>TarımCebimde mobil uygulaması ile tarımla ilgili birçok bilgi ve işlem artık bir tık uzağınızda👇🏻\\n\\nApp Store… https://t.co/J3lWZUoPge</td>\n",
       "      <td>tarımcebimde mobil uygulaması ile tarımla ilgili birçok bilgi ve işlem artık bir tık uzağınızda appstore</td>\n",
       "      <td>many information and transactions related to agriculture with the mobile application in agriculture now are now a click away appstore</td>\n",
       "      <td>many information transactions related agriculture mobile application agriculture click away appstore</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>%25 - %50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Türk Polis Teşkilatı</td>\n",
       "      <td>2023-01-03 08:39:07+00:00</td>\n",
       "      <td>#UYUMA uygulaması ile karşılaştığınız uyuşturucu ticaretini doğrudan ve en hızlı şekilde bildirin!\\n\\nUygulamayı indi… https://t.co/8WaLKZsD5j</td>\n",
       "      <td>uygulaması ile karşılaştığınız uyuşturucu ticaretini doğrudan ve en hızlı şekilde bildirin uygulamayı indi</td>\n",
       "      <td>report the drug trade directly and fastest in the fastest way.</td>\n",
       "      <td>report drug trade directly fastest fastest way.</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>%25 - %50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>müthiş indirim</td>\n",
       "      <td>2023-01-11 16:35:28+00:00</td>\n",
       "      <td>Akıllı Saatler Kısa Süreliğine İndirimde Kaçırmayınn⌚️🔥\\n\\n🔗 https://t.co/tfJO1ZAeQb https://t.co/yx5JcK4Svl</td>\n",
       "      <td>akıllı saatler kısa süreliğine indirimde kaçırmayın</td>\n",
       "      <td>smart watches do not miss for a short time</td>\n",
       "      <td>smart watches miss short time</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>%25 - %50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cigdem Kaya</td>\n",
       "      <td>2023-01-12 02:27:15+00:00</td>\n",
       "      <td>RT @CanSelcuki: Ocak ayı anketi tamamlandı. \\n\\n- AK Parti yükseliş trendi devam ediyor\\n- Kararsızlarda anlamlı bir düşüş var\\n- EYT toplumun…</td>\n",
       "      <td>ocak ayı anketi tamamlandı ak parti yükseliş trendi devam ediyor kararsızlarda anlamlı bir düşüş var eyt toplumun</td>\n",
       "      <td>january survey was completed, the ak party rise trend continues, there is a significant decrease in the undecided.</td>\n",
       "      <td>january survey completed, ak party rise trend continues, significant decrease undecided.</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>%75 - %100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Halit Çelik</td>\n",
       "      <td>2023-01-12 02:26:55+00:00</td>\n",
       "      <td>Benim de oynadığım Futbol Patronu iPhone oyununu bir dene https://t.co/41pSGJjSfc</td>\n",
       "      <td>benim de oynadığım futbol patronu ıphone oyununu bir dene</td>\n",
       "      <td>try the football boss i play a game of iphone.</td>\n",
       "      <td>try football boss play game iphone.</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>%25 - %50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Kullanıcı_Adı                Tweet_Tarih  \\\n",
       "0  T.C. Tarım ve Orman Bakanlığı  2023-01-02 13:23:39+00:00   \n",
       "1           Türk Polis Teşkilatı  2023-01-03 08:39:07+00:00   \n",
       "2                 müthiş indirim  2023-01-11 16:35:28+00:00   \n",
       "3                    Cigdem Kaya  2023-01-12 02:27:15+00:00   \n",
       "4                    Halit Çelik  2023-01-12 02:26:55+00:00   \n",
       "\n",
       "                                                                                                                                             Tweet  \\\n",
       "0          TarımCebimde mobil uygulaması ile tarımla ilgili birçok bilgi ve işlem artık bir tık uzağınızda👇🏻\\n\\nApp Store… https://t.co/J3lWZUoPge   \n",
       "1   #UYUMA uygulaması ile karşılaştığınız uyuşturucu ticaretini doğrudan ve en hızlı şekilde bildirin!\\n\\nUygulamayı indi… https://t.co/8WaLKZsD5j   \n",
       "2                                     Akıllı Saatler Kısa Süreliğine İndirimde Kaçırmayınn⌚️🔥\\n\\n🔗 https://t.co/tfJO1ZAeQb https://t.co/yx5JcK4Svl   \n",
       "3  RT @CanSelcuki: Ocak ayı anketi tamamlandı. \\n\\n- AK Parti yükseliş trendi devam ediyor\\n- Kararsızlarda anlamlı bir düşüş var\\n- EYT toplumun…   \n",
       "4                                                                Benim de oynadığım Futbol Patronu iPhone oyununu bir dene https://t.co/41pSGJjSfc   \n",
       "\n",
       "                                                                                                 Tweet_Degistirilmis  \\\n",
       "0           tarımcebimde mobil uygulaması ile tarımla ilgili birçok bilgi ve işlem artık bir tık uzağınızda appstore   \n",
       "1         uygulaması ile karşılaştığınız uyuşturucu ticaretini doğrudan ve en hızlı şekilde bildirin uygulamayı indi   \n",
       "2                                                                akıllı saatler kısa süreliğine indirimde kaçırmayın   \n",
       "3  ocak ayı anketi tamamlandı ak parti yükseliş trendi devam ediyor kararsızlarda anlamlı bir düşüş var eyt toplumun   \n",
       "4                                                          benim de oynadığım futbol patronu ıphone oyununu bir dene   \n",
       "\n",
       "                                                                                                                            Tweet_Ceviri  \\\n",
       "0  many information and transactions related to agriculture with the mobile application in agriculture now are now a click away appstore   \n",
       "1                                                                         report the drug trade directly and fastest in the fastest way.   \n",
       "2                                                                                             smart watches do not miss for a short time   \n",
       "3                     january survey was completed, the ak party rise trend continues, there is a significant decrease in the undecided.   \n",
       "4                                                                                         try the football boss i play a game of iphone.   \n",
       "\n",
       "                                                                                             Tweet_Ayrı  \\\n",
       "0  many information transactions related agriculture mobile application agriculture click away appstore   \n",
       "1                                                       report drug trade directly fastest fastest way.   \n",
       "2                                                                         smart watches miss short time   \n",
       "3              january survey completed, ak party rise trend continues, significant decrease undecided.   \n",
       "4                                                                   try football boss play game iphone.   \n",
       "\n",
       "       Tür    Yoğunluk  \n",
       "0     Nötr   %25 - %50  \n",
       "1     Nötr   %25 - %50  \n",
       "2     Nötr   %25 - %50  \n",
       "3  Pozitif  %75 - %100  \n",
       "4  Negatif   %25 - %50  "
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Veri=pd.read_csv('textblob_eng_duygu.csv')\n",
    "Veri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "a11359cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kullanıcı_Adı</th>\n",
       "      <th>Tweet_Tarih</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_Degistirilmis</th>\n",
       "      <th>Tweet_Ceviri</th>\n",
       "      <th>Tweet_Ayrı</th>\n",
       "      <th>Tür</th>\n",
       "      <th>Yoğunluk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Oliver Jack</td>\n",
       "      <td>2023-01-12 02:26:09+00:00</td>\n",
       "      <td>https://t.co/s8mWtQwR9G #Buca yalnız zekiyim canlı ise Reşat hırsızların</td>\n",
       "      <td>yalnız zekîyim canlı ise reşat hırsızların</td>\n",
       "      <td>if i am alone, if you are alive, reşat thieves</td>\n",
       "      <td>alone, alive, reşat thieves</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>%25 - %50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hz.Mert</td>\n",
       "      <td>2023-01-12 02:24:43+00:00</td>\n",
       "      <td>@Apple 14 ü çok başarılı yapamamışsınız siz iyisi mi 15 i çıkarın da onu alalım..</td>\n",
       "      <td>u çok başarılı yapamamışsınız siz iyisi mi ı çıkarın da onu alalım</td>\n",
       "      <td>you haven't done it very successful?</td>\n",
       "      <td>done successful?</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>%75 - %100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oliver Jack</td>\n",
       "      <td>2023-01-12 02:18:46+00:00</td>\n",
       "      <td>https://t.co/25IYCAwUzf #Buca bilene  yakarsın gidiyor bilirim fotograf Kitap bile degil</td>\n",
       "      <td>bilene yakarsın gidiyor bilirim fotoğraf kitap bile değil</td>\n",
       "      <td>you know, i know, i know the photo is not even a book</td>\n",
       "      <td>know, know, know photo even book</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>0 - 25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oliver Jack</td>\n",
       "      <td>2023-01-12 02:11:21+00:00</td>\n",
       "      <td>https://t.co/8y7hKi9J4S Gibi sigara #Buca hastaneler</td>\n",
       "      <td>gibi sigara hastaneler</td>\n",
       "      <td>cigarette hospitals like</td>\n",
       "      <td>cigarette hospitals like</td>\n",
       "      <td>Nötr</td>\n",
       "      <td>0 - 25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oliver Jack</td>\n",
       "      <td>2023-01-12 02:03:57+00:00</td>\n",
       "      <td>https://t.co/PKozS01mG2 Dinleyenler Düşünmek daha beklemek resmen göre Schopenhauer tohumudur #Buca bilir iyi</td>\n",
       "      <td>dinleyenler düşünmek daha beklemek resmen göre schopenhauer tohumudur bilir iyi</td>\n",
       "      <td>listening to think more to wait more than the schopenhauer seed knows good.</td>\n",
       "      <td>listening think wait schopenhauer seed knows good.</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>%50 - %75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kullanıcı_Adı                Tweet_Tarih  \\\n",
       "5   Oliver Jack  2023-01-12 02:26:09+00:00   \n",
       "6       Hz.Mert  2023-01-12 02:24:43+00:00   \n",
       "7   Oliver Jack  2023-01-12 02:18:46+00:00   \n",
       "8   Oliver Jack  2023-01-12 02:11:21+00:00   \n",
       "9   Oliver Jack  2023-01-12 02:03:57+00:00   \n",
       "\n",
       "                                                                                                           Tweet  \\\n",
       "5                                       https://t.co/s8mWtQwR9G #Buca yalnız zekiyim canlı ise Reşat hırsızların   \n",
       "6                              @Apple 14 ü çok başarılı yapamamışsınız siz iyisi mi 15 i çıkarın da onu alalım..   \n",
       "7                       https://t.co/25IYCAwUzf #Buca bilene  yakarsın gidiyor bilirim fotograf Kitap bile degil   \n",
       "8                                                           https://t.co/8y7hKi9J4S Gibi sigara #Buca hastaneler   \n",
       "9  https://t.co/PKozS01mG2 Dinleyenler Düşünmek daha beklemek resmen göre Schopenhauer tohumudur #Buca bilir iyi   \n",
       "\n",
       "                                                               Tweet_Degistirilmis  \\\n",
       "5                                       yalnız zekîyim canlı ise reşat hırsızların   \n",
       "6               u çok başarılı yapamamışsınız siz iyisi mi ı çıkarın da onu alalım   \n",
       "7                        bilene yakarsın gidiyor bilirim fotoğraf kitap bile değil   \n",
       "8                                                           gibi sigara hastaneler   \n",
       "9  dinleyenler düşünmek daha beklemek resmen göre schopenhauer tohumudur bilir iyi   \n",
       "\n",
       "                                                                  Tweet_Ceviri  \\\n",
       "5                               if i am alone, if you are alive, reşat thieves   \n",
       "6                                         you haven't done it very successful?   \n",
       "7                        you know, i know, i know the photo is not even a book   \n",
       "8                                                     cigarette hospitals like   \n",
       "9  listening to think more to wait more than the schopenhauer seed knows good.   \n",
       "\n",
       "                                           Tweet_Ayrı      Tür    Yoğunluk  \n",
       "5                         alone, alive, reşat thieves     Nötr   %25 - %50  \n",
       "6                                    done successful?  Pozitif  %75 - %100  \n",
       "7                    know, know, know photo even book     Nötr     0 - 25%  \n",
       "8                            cigarette hospitals like     Nötr     0 - 25%  \n",
       "9  listening think wait schopenhauer seed knows good.  Pozitif   %50 - %75  "
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Veri.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "a62d44e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Argo cümle\\nmodel_path =\"martin-ha/toxic-comment-model\"\\ntokenizer=AutoTokenizer.from_pretrained(model_path)\\nmodel=AutoModelForSequenceClassification.from_pretrained(model_path)\\npipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\\ntext=\"bu cümle toksik bir cümle değil amınakoyayım\"\\nb_text=TextBlob(text)\\ne_text=b_text.translate(from_lang=\\'tr\\', to=\\'en\\')  \\nsonuc=pipeline(str(e_text))\\nif sonuc[0][\\'label\\']==\"toxic\":\\n    print (\"Toxic\")\\nelse:\\n    print (\"Toxic değil\")'"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Argo cümle\n",
    "model_path =\"martin-ha/toxic-comment-model\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "pipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "text=\"bu cümle toksik bir cümle değil amınakoyayım\"\n",
    "b_text=TextBlob(text)\n",
    "e_text=b_text.translate(from_lang='tr', to='en')  \n",
    "sonuc=pipeline(str(e_text))\n",
    "if sonuc[0]['label']==\"toxic\":\n",
    "    print (\"Toxic\")\n",
    "else:\n",
    "    print (\"Toxic değil\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "06dea2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Cursor in module tweepy.cursor:\n",
      "\n",
      "class Cursor(builtins.object)\n",
      " |  Cursor(method, *args, **kwargs)\n",
      " |  \n",
      " |  :class:`Cursor` can be used to paginate for any :class:`API` methods that\n",
      " |  support pagination\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  method\n",
      " |      :class:`API` method to paginate for\n",
      " |  args\n",
      " |      Positional arguments to pass to ``method``\n",
      " |  kwargs\n",
      " |      Keyword arguments to pass to ``method``\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, method, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  items(self, limit=inf)\n",
      " |      Retrieve the items in each page/request\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit\n",
      " |          Maximum number of items to iterate over\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ItemIterator\n",
      " |          Iterator to iterate through items\n",
      " |  \n",
      " |  pages(self, limit=inf)\n",
      " |      Retrieve the page for each request\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit\n",
      " |          Maximum number of pages to iterate over\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      CursorIterator or DMCursorIterator or IdIterator or NextIterator or         PageIterator\n",
      " |          Iterator to iterate through pages\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tweepy.Cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "82299eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eksik Cümle\n",
    "unmasker=pipeline('fill-mask', model='xlm-roberta-base')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
