{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50cb347",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install nltk\n",
    "%pip install tweepy\n",
    "%pip install pandas\n",
    "%pip install wordcloud\n",
    "%pip install textblob\n",
    "%pip install seaborn\n",
    "%pip install poyraz\n",
    "%pip install spacy\n",
    "%pip install sklearn\n",
    "%pip install zemberek-python\n",
    "%pip install trnltk\n",
    "%pip install git+https://github.com/emres/turkish-deasciifier.git\n",
    "%pip install transformers datasets\n",
    "%pip install torch\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f73c9b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cemke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*-coding:utf-8-*-\n",
    "from zemberek import (\n",
    "    TurkishSpellChecker,\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishTokenizer\n",
    ")\n",
    "import logging\n",
    "import tweepy\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "import string\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import Stream\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "from trnlp import TrnlpWord\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, TextClassificationPipeline\n",
    "from transformers import pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "31c724d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getTweets:\n",
    "    def __init__(self,ckey,csecret,atoken,asecret):\n",
    "        self.api=None\n",
    "        self.consumer_key = ckey\n",
    "        self.consumer_secret = csecret\n",
    "        self.access_token = atoken\n",
    "        self.access_token_secret = asecret\n",
    "        \n",
    "    def setAuth(self):\n",
    "        try:\n",
    "            self.auth = tweepy.OAuthHandler(self.consumer_key, self.consumer_secret)\n",
    "            self.auth.set_access_token(self.access_token, self.access_token_secret)\n",
    "            self.api = tweepy.API(self.auth)            \n",
    "            print (\"Baƒülantƒ± Yapƒ±ldƒ±!\")                           \n",
    "        except tweepy.TweepError as err:\n",
    "            print('Error: {}'.format(err))   \n",
    "    \n",
    "    def toDataFrame(tweets):\n",
    "        try:\n",
    "            print (\"Veriler Kayƒ±t Ediliyor...\")\n",
    "            pd.set_option('display.max_rows', None)\n",
    "            pd.set_option('display.max_columns', None)\n",
    "            pd.set_option('display.width', None)\n",
    "            pd.set_option('display.max_colwidth', None)\n",
    "            DataSet = pd.DataFrame()\n",
    "\n",
    "            DataSet['Kullanƒ±cƒ±_Adƒ±'] = [tweet.user.name for tweet in tweets]\n",
    "            DataSet['Tweet_Tarih'] = [tweet.created_at for tweet in tweets]   \n",
    "            #DataSet['Tweet_Id'] = [tweet.id for tweet in tweets]\n",
    "            DataSet['Tweet'] = [tweet.text for tweet in tweets]\n",
    "            DataSet['Tweet_Degistirilmis'] = [tweet.text for tweet in tweets]\n",
    "            DataSet['Tweet_Ceviri']=[tweet.text for tweet in tweets]            \n",
    "            #DataSet['Kullanƒ±cƒ±_Id'] = [tweet.user.id for tweet in tweets]  \n",
    "                \n",
    "            #DataSet['Dil'] = [tweet.lang for tweet in tweets]\n",
    "            print (\"Veriler Kayƒ±t Edildi!\")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "    \n",
    "    def searchTweet(self,aranan):\n",
    "        self.setAuth()\n",
    "        try:                      \n",
    "            print (\"Kelimeye Uygun Tweetler Sorgulanƒ±yor...\")\n",
    "            cursor = tweepy.Cursor(self.api.search_tweets, q=aranan, result_type=\"new\", lang='tr')\n",
    "            results=[]\n",
    "            for item in cursor.items(10):\n",
    "                results.append(item)\n",
    "            print (\"Kelimeye Uygun Tweetler Sorgulandƒ±!\")\n",
    "            DataSet = getTweets.toDataFrame(results)  \n",
    "            DataSet.to_csv('tw.csv',index=False)\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "        finally:\n",
    "            Dataset=pd.read_csv('tw.csv')                   \n",
    "            getTweets.TweetClear(DataSet)\n",
    "            getTweets.SentenceNormalization(DataSet)\n",
    "            getTweets.TweetTranslate(DataSet)\n",
    "            getTweets.KelimeAyristirma(DataSet) \n",
    "            getTweets.ToxicSentiment(DataSet)\n",
    "            getTweets.TextblobSentiment(DataSet)\n",
    "\n",
    "    def TextblobSentiment(DataSet):\n",
    "        try:\n",
    "            print (\"Duygu Analizi Yapƒ±lƒ±yor...\")\n",
    "            Veri=DataSet\n",
    "            Veri[\"T√ºr\"] = Veri[\"Tweet_Ayrƒ±\"].apply(getTweets.getPolarity)\n",
    "            Veri[\"Yoƒüunluk\"] = Veri[\"Tweet_Ayrƒ±\"].apply(getTweets.getSubjectivity)\n",
    "            Veri.to_csv('textblob_eng_duygu.csv',index=False)\n",
    "            print(\"Duygu Analizi Yapƒ±ldƒ±!\")                        \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \n",
    "            \n",
    "    \"\"\"def TrSentiment(DataSet):\n",
    "        try:\n",
    "            print(\"T√ºrk√ße Duygu Analizi Yapƒ±lƒ±yor...\")\n",
    "            for example,index in DataSet[\"Tweet_Degistirilmis\"]:\n",
    "                DataSet[\"TR_A\"][index] = simple_token(example, sw=stopwords)\n",
    "            print(\"T√ºrk√ße Duygu Analizi Yapƒ±ldƒ±!\")\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err)) \"\"\"\n",
    "                     \n",
    "    def TweetTranslate(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print (\"Tweetler √áeviriliyor...\")\n",
    "            for index in range(len(data[\"Tweet_Degistirilmis\"])):\n",
    "                Ceviri_Blob=TextBlob(data[\"Tweet_Degistirilmis\"][index])\n",
    "                Eng_Blob=Ceviri_Blob.translate(from_lang='tr', to='en')  \n",
    "                data[\"Tweet_Ceviri\"][index]=Eng_Blob.lower()\n",
    "                \n",
    "            print (\"Tweetler √áevirildi!\")                      \n",
    "            return DataSet        \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def TweetClear(DataSet):\n",
    "        try:\n",
    "            print (\"Tweetler Temizleniyor...\")\n",
    "            pattern = re.compile('http[s]?://(?:[a-zA-Z0-9ƒü√º≈ü√∂√ßƒ±ƒ∞ƒû√ú≈û√ñ√á]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F]))+|#[a-zA-Z0-9ƒü√º≈ü√∂√ßƒ±ƒ∞ƒû√ú≈û√ñ√á]+|$[a-zA-Z0-9ƒü√º≈ü√∂√ßƒ±ƒ∞ƒû√ú≈û√ñ√á]+|@[a-zA-Z0-9ƒü√º≈ü√∂√ßƒ±ƒ∞ƒû√ú≈û√ñ√á_]+|[,.^_$*%-;È∂Ø!?‚Äô\"‚Äú‚Äù:=|‚Ä¶#]+|\\n+|RT[\\s]+|amp[\\s]+|(^gt)')\n",
    "            for index in range(len(DataSet[\"Tweet_Degistirilmis\"])):        \n",
    "                DataSet[\"Tweet_Degistirilmis\"][index]=pattern.sub(' ', DataSet[\"Tweet_Degistirilmis\"][index])    \n",
    "                DataSet[\"Tweet_Degistirilmis\"][index]=DataSet[\"Tweet_Degistirilmis\"][index].lower()              \n",
    "            DataSet[\"Tweet_Degistirilmis\"]=DataSet[\"Tweet_Degistirilmis\"].str.replace(\"[^\\w\\s]\",\"\")\n",
    "            print (\"Tweetler Temizlendi!\")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def SentenceNormalization(DataSet):\n",
    "        try:\n",
    "            morphology = TurkishMorphology.create_with_defaults()\n",
    "            normalizer = TurkishSentenceNormalizer(morphology)\n",
    "            for data,index in DataSet[\"Tweet_Degistirilmis\"].items():\n",
    "                 DataSet[\"Tweet_Degistirilmis\"][index]= normalizer.normalize(data)\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def KelimeAyristirma(DataSet):\n",
    "        try:\n",
    "            stop = stopwords.words('english')\n",
    "            DataSet[\"Tweet_Ayrƒ±\"] = DataSet[\"Tweet_Ceviri\"].str.split()\n",
    "            DataSet[\"Tweet_Ayrƒ±\"] = DataSet[\"Tweet_Ayrƒ±\"].apply(lambda x: [item for item in x if item not in stop])\n",
    "            DataSet[\"Tweet_Ayrƒ±\"] = DataSet[\"Tweet_Ayrƒ±\"].str.join(\" \")\n",
    "            return DataSet\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "    \n",
    "    def ToxicSentiment(DataSet):\n",
    "        try:\n",
    "            data=DataSet\n",
    "            print(\"Toxic C√ºmle Analizi Yapƒ±lƒ±yor...\")\n",
    "            model_path =\"martin-ha/toxic-comment-model\"\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "            model=AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "            pipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "            for examples, index in data[\"Tweet_Ceviri\"].items():\n",
    "                sonuc=pipeline(str(examples))\n",
    "                if sonuc[0]['label']==\"toxic\":\n",
    "                    data[\"Tweet_Toxic\"][index]=\"Toxic\"\n",
    "                else:\n",
    "                    data[\"Tweet_Toxic\"][index]=\"Toxic deƒüil\"    \n",
    "            print(\"Toxic C√ºmle Analizi Yapƒ±ldƒ±!\")\n",
    "            return DataSet  \n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "        \n",
    "    def getSubjectivity(DataSet):\n",
    "        try: \n",
    "            sub=TextBlob(DataSet).sentiment.subjectivity               \n",
    "            if sub >=0.75:\n",
    "                return \"Kesinlikle\"\n",
    "            elif sub >=0.5 and sub <0.75:\n",
    "                return \"Y√ºksek ƒ∞htimal\"\n",
    "            elif sub >=0.25 and sub <0.50:\n",
    "                return \"D√º≈ü√ºk ƒ∞htimal\"\n",
    "            else:\n",
    "                return \"Kesin Deƒüil\"\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))\n",
    "            \n",
    "    def getPolarity(DataSet):\n",
    "        try:\n",
    "            pol=TextBlob(DataSet).sentiment.polarity\n",
    "            if pol>0.1:\n",
    "                return \"Pozitif\"\n",
    "            elif pol<-0.1:\n",
    "                return \"Negatif\"\n",
    "            else:\n",
    "                return \"N√∂tr\"\n",
    "        except Exception as err:\n",
    "            print('Error: {}'.format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "cc4db959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baƒülantƒ± Yapƒ±ldƒ±!\n",
      "Kelimeye Uygun Tweetler Sorgulanƒ±yor...\n",
      "Kelimeye Uygun Tweetler Sorgulandƒ±!\n",
      "Veriler Kayƒ±t Ediliyor...\n",
      "Veriler Kayƒ±t Edildi!\n",
      "Tweetler Temizleniyor...\n",
      "Tweetler Temizlendi!\n",
      "2023-01-12 03:31:25,805 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 9.799805402755737\n",
      "\n",
      "Error: 'int' object has no attribute 'translate'\n",
      "Tweetler √áeviriliyor...\n",
      "Tweetler √áevirildi!\n",
      "Toxic C√ºmle Analizi Yapƒ±lƒ±yor...\n",
      "Error: 'Tweet_Toxic'\n",
      "Duygu Analizi Yapƒ±lƒ±yor...\n",
      "Duygu Analizi Yapƒ±ldƒ±!\n"
     ]
    }
   ],
   "source": [
    "tw = getTweets( \n",
    "ckey = 'o7qidRODRWm5u07PtAWrCpSqf',\n",
    "csecret = '1Yn60OYMJl5kRCSM0XQ4Lskxh6hjM4VMz51OdsS6dM9DQuQ4MV',\n",
    "atoken = '1315792402234441730-Dt7AydgVGYI5VN9RRQfnR8Endh0WAc',\n",
    "asecret = 'jhfiDfB53Z27EqHfvfKbNdo0w2SWLqyyoAkILqgSoaGMK'\n",
    ")\n",
    "aranan=input(\"Aranacak Kelimeyi Girin: \")\n",
    "tw.searchTweet(aranan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "e018df1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kullanƒ±cƒ±_Adƒ±</th>\n",
       "      <th>Tweet_Tarih</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_Degistirilmis</th>\n",
       "      <th>Tweet_Ceviri</th>\n",
       "      <th>Tweet_Ayrƒ±</th>\n",
       "      <th>T√ºr</th>\n",
       "      <th>Yoƒüunluk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ô°üçãüçä</td>\n",
       "      <td>2023-01-11 23:54:02+00:00</td>\n",
       "      <td>RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken‚Ä¶</td>\n",
       "      <td>kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken</td>\n",
       "      <td>burning a bulb in his head after the enlightenment of the rice shop to offer the offer ls≈üskdkskcodk this child aybiken</td>\n",
       "      <td>burning bulb head enlightenment rice shop offer offer ls≈üskdkskcodk child aybiken</td>\n",
       "      <td>N√∂tr</td>\n",
       "      <td>Kesin Deƒüil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfa</td>\n",
       "      <td>2023-01-11 23:31:22+00:00</td>\n",
       "      <td>@TamerAkyuz5 @ankara_kusu Yok edisonun bulduƒüu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim</td>\n",
       "      <td>yok edisonun bulduƒüu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim</td>\n",
       "      <td>the bulb found by the destruction of the destruction is the religion that god speaks and they are well pqzarla≈ülar ed jina veinim</td>\n",
       "      <td>bulb found destruction destruction religion god speaks well pqzarla≈ülar ed jina veinim</td>\n",
       "      <td>N√∂tr</td>\n",
       "      <td>Kesin Deƒüil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ôº•Ôº¨Ôº°</td>\n",
       "      <td>2023-01-11 23:20:59+00:00</td>\n",
       "      <td>RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken‚Ä¶</td>\n",
       "      <td>kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken</td>\n",
       "      <td>burning a bulb in his head after the enlightenment of the rice shop to offer the offer ls≈üskdkskcodk this child aybiken</td>\n",
       "      <td>burning bulb head enlightenment rice shop offer offer ls≈üskdkskcodk child aybiken</td>\n",
       "      <td>N√∂tr</td>\n",
       "      <td>Kesin Deƒüil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kullanƒ±cƒ±_Adƒ±                Tweet_Tarih  \\\n",
       "0           ‚ô°üçãüçä  2023-01-11 23:54:02+00:00   \n",
       "1          alfa  2023-01-11 23:31:22+00:00   \n",
       "2           Ôº•Ôº¨Ôº°  2023-01-11 23:20:59+00:00   \n",
       "\n",
       "                                                                                                                                          Tweet  \\\n",
       "0  RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken‚Ä¶   \n",
       "1                    @TamerAkyuz5 @ankara_kusu Yok edisonun bulduƒüu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim   \n",
       "2  RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken‚Ä¶   \n",
       "\n",
       "                                                                                                             Tweet_Degistirilmis  \\\n",
       "0      kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken    \n",
       "1                               yok edisonun bulduƒüu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim   \n",
       "2      kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken    \n",
       "\n",
       "                                                                                                                        Tweet_Ceviri  \\\n",
       "0            burning a bulb in his head after the enlightenment of the rice shop to offer the offer ls≈üskdkskcodk this child aybiken   \n",
       "1  the bulb found by the destruction of the destruction is the religion that god speaks and they are well pqzarla≈ülar ed jina veinim   \n",
       "2            burning a bulb in his head after the enlightenment of the rice shop to offer the offer ls≈üskdkskcodk this child aybiken   \n",
       "\n",
       "                                                                               Tweet_Ayrƒ±  \\\n",
       "0       burning bulb head enlightenment rice shop offer offer ls≈üskdkskcodk child aybiken   \n",
       "1  bulb found destruction destruction religion god speaks well pqzarla≈ülar ed jina veinim   \n",
       "2       burning bulb head enlightenment rice shop offer offer ls≈üskdkskcodk child aybiken   \n",
       "\n",
       "    T√ºr     Yoƒüunluk  \n",
       "0  N√∂tr  Kesin Deƒüil  \n",
       "1  N√∂tr  Kesin Deƒüil  \n",
       "2  N√∂tr  Kesin Deƒüil  "
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Veri=pd.read_csv('textblob_eng_duygu.csv')\n",
    "Veri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "a11359cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kullanƒ±cƒ±_Adƒ±</th>\n",
       "      <th>Tweet_Tarih</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_Degistirilmis</th>\n",
       "      <th>Tweet_Ceviri</th>\n",
       "      <th>Tweet_Ayrƒ±</th>\n",
       "      <th>T√ºr</th>\n",
       "      <th>Yoƒüunluk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ô°üçãüçä</td>\n",
       "      <td>2023-01-11 23:54:02+00:00</td>\n",
       "      <td>RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken‚Ä¶</td>\n",
       "      <td>kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken</td>\n",
       "      <td>burning a bulb in his head after the enlightenment of the rice shop to offer the offer ls≈üskdkskcodk this child aybiken</td>\n",
       "      <td>burning bulb head enlightenment rice shop offer offer ls≈üskdkskcodk child aybiken</td>\n",
       "      <td>N√∂tr</td>\n",
       "      <td>Kesin Deƒüil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfa</td>\n",
       "      <td>2023-01-11 23:31:22+00:00</td>\n",
       "      <td>@TamerAkyuz5 @ankara_kusu Yok edisonun bulduƒüu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim</td>\n",
       "      <td>yok edisonun bulduƒüu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim</td>\n",
       "      <td>the bulb found by the destruction of the destruction is the religion that god speaks and they are well pqzarla≈ülar ed jina veinim</td>\n",
       "      <td>bulb found destruction destruction religion god speaks well pqzarla≈ülar ed jina veinim</td>\n",
       "      <td>N√∂tr</td>\n",
       "      <td>Kesin Deƒüil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ôº•Ôº¨Ôº°</td>\n",
       "      <td>2023-01-11 23:20:59+00:00</td>\n",
       "      <td>RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken‚Ä¶</td>\n",
       "      <td>kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken</td>\n",
       "      <td>burning a bulb in his head after the enlightenment of the rice shop to offer the offer ls≈üskdkskcodk this child aybiken</td>\n",
       "      <td>burning bulb head enlightenment rice shop offer offer ls≈üskdkskcodk child aybiken</td>\n",
       "      <td>N√∂tr</td>\n",
       "      <td>Kesin Deƒüil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kullanƒ±cƒ±_Adƒ±                Tweet_Tarih  \\\n",
       "0           ‚ô°üçãüçä  2023-01-11 23:54:02+00:00   \n",
       "1          alfa  2023-01-11 23:31:22+00:00   \n",
       "2           Ôº•Ôº¨Ôº°  2023-01-11 23:20:59+00:00   \n",
       "\n",
       "                                                                                                                                          Tweet  \\\n",
       "0  RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken‚Ä¶   \n",
       "1                    @TamerAkyuz5 @ankara_kusu Yok edisonun bulduƒüu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim   \n",
       "2  RT @simaldiyebiri: Kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken‚Ä¶   \n",
       "\n",
       "                                                                                                             Tweet_Degistirilmis  \\\n",
       "0      kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken    \n",
       "1                               yok edisonun bulduƒüu ampul allahin bahsettigi din var ve ikisini iyi pqzarliyorlar ed jina venim   \n",
       "2      kafasinda ampul yanmali bi aydinlanma yasadiktan sonra pilav dukkani acmayi teklif etmesi ls≈üskdkskcodk bu cocuk aybiken    \n",
       "\n",
       "                                                                                                                        Tweet_Ceviri  \\\n",
       "0            burning a bulb in his head after the enlightenment of the rice shop to offer the offer ls≈üskdkskcodk this child aybiken   \n",
       "1  the bulb found by the destruction of the destruction is the religion that god speaks and they are well pqzarla≈ülar ed jina veinim   \n",
       "2            burning a bulb in his head after the enlightenment of the rice shop to offer the offer ls≈üskdkskcodk this child aybiken   \n",
       "\n",
       "                                                                               Tweet_Ayrƒ±  \\\n",
       "0       burning bulb head enlightenment rice shop offer offer ls≈üskdkskcodk child aybiken   \n",
       "1  bulb found destruction destruction religion god speaks well pqzarla≈ülar ed jina veinim   \n",
       "2       burning bulb head enlightenment rice shop offer offer ls≈üskdkskcodk child aybiken   \n",
       "\n",
       "    T√ºr     Yoƒüunluk  \n",
       "0  N√∂tr  Kesin Deƒüil  \n",
       "1  N√∂tr  Kesin Deƒüil  \n",
       "2  N√∂tr  Kesin Deƒüil  "
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Veri.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "a62d44e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Argo c√ºmle\\nmodel_path =\"martin-ha/toxic-comment-model\"\\ntokenizer=AutoTokenizer.from_pretrained(model_path)\\nmodel=AutoModelForSequenceClassification.from_pretrained(model_path)\\npipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\\ntext=\"bu c√ºmle toksik bir c√ºmle deƒüil amƒ±nakoyayƒ±m\"\\nb_text=TextBlob(text)\\ne_text=b_text.translate(from_lang=\\'tr\\', to=\\'en\\')  \\nsonuc=pipeline(str(e_text))\\nif sonuc[0][\\'label\\']==\"toxic\":\\n    print (\"Toxic\")\\nelse:\\n    print (\"Toxic deƒüil\")'"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Argo c√ºmle\n",
    "model_path =\"martin-ha/toxic-comment-model\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "pipeline=TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "text=\"bu c√ºmle toksik bir c√ºmle deƒüil amƒ±nakoyayƒ±m\"\n",
    "b_text=TextBlob(text)\n",
    "e_text=b_text.translate(from_lang='tr', to='en')  \n",
    "sonuc=pipeline(str(e_text))\n",
    "if sonuc[0]['label']==\"toxic\":\n",
    "    print (\"Toxic\")\n",
    "else:\n",
    "    print (\"Toxic deƒüil\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "82299eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eksik C√ºmle\n",
    "unmasker=pipeline('fill-mask', model='xlm-roberta-base')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
